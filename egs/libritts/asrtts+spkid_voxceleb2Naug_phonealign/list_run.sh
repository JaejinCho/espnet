mkdir log

# 1. Data prep: spkloss_weight does not matter specified here in data prep.
## Generate symlinks for {dump,data,exp} directories to distribute data over nodes
mkdir -p /export/b15/jcho/espnet3/egs/libritts/asrtts+spkid_voxceleb2_phonealign/{dump,data,exp}
for dname in `ls -d /export/b15/jcho/espnet3/egs/libritts/asrtts+spkid_voxceleb2_phonealign/{dump,data,exp}`;do
    ln -s ${dname} $(basename ${dname})
done
## Actual run for data prep.
(DONE, *** only for the first run ***) bash run.asrttsspkid.sh --stage 0 --stop_stage 2 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/dataprep.stagefrom0to2.log
cp /export/b18/jcho/espnet3/egs/libritts/asrtts+spkid_voxceleb1_kaldiasr_phonealign_rf3/conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_bs56.yaml conf/
## Working on adding original samples for noise-augmented samples to data.json
### 1. Create feat2orifeat.scp
. path.sh
if [ ! -d dump/voxceleb2Naug ]; then
    mkdir -p dump/voxceleb2Naug && cat dump/voxceleb2Naug_{train,dev}/feats.scp > dump/voxceleb2Naug/feats.scp
fi
python gen_utt2orilink.py dump/voxceleb2Naug/feats.scp data/voxceleb2Naug_train/utt2spk dump/voxceleb2Naug_train/utt2orilink
python gen_utt2orilink.py dump/voxceleb2Naug/feats.scp data/voxceleb2Naug_dev/utt2spk dump/voxceleb2Naug_dev/utt2orilink
### 2. Update the data.json: This step is done in run.*.sh



# 2. Training (2flstm512Nusecat + shufflebathcing (fixed bs) + fullyunsync with spkloss_weight=0.03 and nceloss=0.001)
## 1) Speaker ID only
(DONE) bash run.spkidonly.sh --train_config conf/train_pytorch_tacotron2+spkemb_spkidonly_shufflebatching_bs128.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --ttsloss_weight 0 --spkloss_weight 1 2>&1 | tee log/run.spkidonly.onlystage4.unsync.shufflebatching.bs128.log
(ING RESUMMED with self.it=961200, nceloss_weight=1) bash run.spkidonly_nceloss.sh --cuda_memsize 20 --resume exp/voxceleb2Naug_train_train_pytorch_tacotron2+spkemb_spkidonly_nceloss_shufflebatching_bs76_spkloss_weight1_nceloss_weight1_unsync/results/snapshot.ep.38 --train_config conf/train_pytorch_tacotron2+spkemb_spkidonly_nceloss_shufflebatching_bs76.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --ttsloss_weight 0 --spkloss_weight 1 --nceloss_weight 1 2>&1 | tee log/run.spkidonly_nceloss1.onlystage4.unsync.shufflebatching.bs76.resumefromep.38.log
(ING, nceloss_weight=0.1) bash run.spkidonly_nceloss.sh --train_config conf/train_pytorch_tacotron2+spkemb_spkidonly_nceloss_shufflebatching_bs76.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --ttsloss_weight 0 --spkloss_weight 1 --nceloss_weight 0.1 2>&1 | tee log/run.spkidonly_nceloss0.1.onlystage4.unsync.shufflebatching.bs76.log
(ING RESUMMED (--mem 20G) with self.it=379500, nceloss_weight=0.03) bash run.spkidonly_nceloss.sh --cuda_memsize 20 --resume exp/voxceleb2Naug_train_train_pytorch_tacotron2+spkemb_spkidonly_nceloss_shufflebatching_bs76_spkloss_weight1_nceloss_weight0.03_unsync/results/snapshot.ep.15 --train_config conf/train_pytorch_tacotron2+spkemb_spkidonly_nceloss_shufflebatching_bs76.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --ttsloss_weight 0 --spkloss_weight 1 --nceloss_weight 0.03 2>&1 | tee log/run.spkidonly_nceloss0.03.onlystage4.unsync.shufflebatching.bs76.resumefromep.15.log
## 2) Speaker ID + TTS (cleanrecon)
(STOPPED due to less memory request (10G), ING) bash run.asrttsspkid.cleanrecon.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.cleanrecon.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching.bs64.log
(RERUNNING description below: mem=20G, *** temporal change of self.it=0 to 193100 (This setup moved back again to 0) ***)
(DONE) bash run.asrttsspkid.cleanrecon.sh --resume exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_spkloss_weight0.03_fullyunsync_cleanrecon/results/snapshot.ep.5 --cuda_memsize 20 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.cleanrecon.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching.bs64.mem20G.itsetup193100.log
### TTS only - start
(ING) bash run.asrttsspkid.cleanrecon.sh --cuda_memsize 20 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.cleanrecon.spkloss_weight0.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching.bs64.mem20G.log
### TTS only - end
(DONE: Start from ep.11 w/ lr=1e-4 self.it=360500, due to sudden large increase in loss at ep.12) bash run.asrttsspkid.cleanrecon.sh --resume exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_spkloss_weight0.03_fullyunsync_cleanrecon/results/snapshot.ep.11 --cuda_memsize 20 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_lr1e-4.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.cleanrecon.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching.bs64.mem20G.resumeWlr1e-4.modelalllossbest.log
(DONE: like above but initialize optimizer while starting from the snapshot) bash run.asrttsspkid.cleanrecon.sh --resume exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_spkloss_weight0.03_fullyunsync_cleanrecon/results/snapshot.ep.11 --cuda_memsize 20 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_lr1e-4_initopt.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.cleanrecon.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching.bs64.mem20G.resumeWlr1e-4_initopt.modelalllossbest.log
(DONE: Start from the ep.12 w/ lr=1e-5 (from lr=1e-4 right above) self.it=360500) bash run.asrttsspkid.cleanrecon.sh --resume exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_lr1e-4_initopt_spkloss_weight0.03_fullyunsync_cleanrecon/results/snapshot.ep.12 --cuda_memsize 20 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_lr1e-5_initopt.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.cleanrecon.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching.bs64.mem20G.resumeWlr1e-5_initopt.modelalllossbest.log
(ING: Start from the ep.21 (bestlossmodel among 30 epochs) w/ lr=1e-5 (from lr=1e-4 2 lines above) self.it=630900) bash run.asrttsspkid.cleanrecon.sh --tag fromep21 --resume exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_lr1e-4_initopt_spkloss_weight0.03_fullyunsync_cleanrecon/results/snapshot.ep.21 --cuda_memsize 20 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_lr1e-5_initopt.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.cleanrecon.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching.bs64.mem20G.resumeWlr1e-5_initopt_fromep21.modellossbest.log
## 3) Speaker ID + TTS (cleanrecon) + NCE
(STOPPED by MISTAKE) bash run.asrttsspkid_nceloss.cleanrecon.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_cleanrecon_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid_nceloss.cleanrecon.spkloss_weight0.03.nceloss_weight0.001.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching.bs56.log
(RERUNNING description below:, *** temporal change of self.it=0 to 193100 (This setup moved back again to 0) ***). ********** NOTE: When I resume from a snapshot, the snapshot generated again first and marked to the log file **************
(DONE: STOPPED after ep.15 due to nan grad. norm.) bash run.asrttsspkid_nceloss.cleanrecon.sh --resume exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_cleanrecon_bs56_spkloss_weight0.03_nceloss_weight0.001_fullyunsync_cleanrecon/results/snapshot.ep.5 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_cleanrecon_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid_nceloss.cleanrecon.spkloss_weight0.03.nceloss_weight0.001.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching.bs56.itsetup193100.log
### TTS only + NCE - start
(ING) bash run.asrttsspkid_nceloss.cleanrecon.sh --cuda_memsize 20 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_cleanrecon_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid_nceloss.cleanrecon.spkloss_weight0.nceloss_weight0.001.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching.bs56.log
### TTS only + NCE - end
(ING: Start from ep.12 w/ lr=1e-4 self.it=411900, due to sudden large increase in loss at ep.13 (This happened because gradnorm started to become nan in the early iterations of snapshot.ep.12. ******* NOTE *******: sudden large increase happened at the similar point as spkid + tts W/O nce)) bash run.asrttsspkid_nceloss.cleanrecon.sh --resume exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_cleanrecon_bs56_spkloss_weight0.03_nceloss_weight0.001_fullyunsync_cleanrecon/results/snapshot.ep.12 --cuda_memsize 20 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_cleanrecon_bs56_lr1e-4_initopt.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid_nceloss.cleanrecon.spkloss_weight0.03.nceloss_weight0.001.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching.bs56.mem20G.resumeWlr1e-4_initopt.snapshot.ep.12.log
### error runs (DISREGARD)
(STOPPED) bash run.asrttsspkid.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid.spkloss_weight0.03.nceloss_weight0.001.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching.bs56.log
(STOPPED. error due to validation phase, cleanrecon (*** Correctly ran but ran before script names were changed to include cleanrecon) bash run.asrttsspkid.cleanrecon.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_cleanrecon_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid.cleanrecon.spkloss_weight0.03.nceloss_weight0.001.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching.bs56.log



# 3. Backend
## SPKID only
### W/ voxceleb2Naug
(DONE: 2.20, current bestspkidlossNspkidacc, snapshot.ep.16) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --model snapshot.ep.16 --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_train_pytorch_tacotron2+spkemb_spkidonly_shufflebatching_bs128_spkloss_weight1_unsync/ 2>&1 | tee log/backend.voxceleb2Naug_train_train_pytorch_tacotron2+spkemb_spkidonly_shufflebatching_bs128_spkloss_weight1_unsync.bestspkidlossNspkidacc.snapshot.ep.16.log
(DONE: 2.07, bestspkidlossNspkidacc among 30 epochs, snapshot.ep.30) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --model snapshot.ep.30 --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_train_pytorch_tacotron2+spkemb_spkidonly_shufflebatching_bs128_spkloss_weight1_unsync/ 2>&1 | tee log/backend.voxceleb2Naug_train_train_pytorch_tacotron2+spkemb_spkidonly_shufflebatching_bs128_spkloss_weight1_unsync.bestspkidlossNspkidaccAmong30epochs.snapshot.ep.30.log
(DONE: 1.92 , bestspkidloss, snapshot.ep.49) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --model snapshot.ep.49 --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_train_pytorch_tacotron2+spkemb_spkidonly_shufflebatching_bs128_spkloss_weight1_unsync/ 2>&1 | tee log/backend.voxceleb2Naug_train_train_pytorch_tacotron2+spkemb_spkidonly_shufflebatching_bs128_spkloss_weight1_unsync.bestspkidloss.snapshot.ep.49.log
(DONE: 1.87 , bestspkidacc, snapshot.ep.47) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --model snapshot.ep.47 --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_train_pytorch_tacotron2+spkemb_spkidonly_shufflebatching_bs128_spkloss_weight1_unsync/ 2>&1 | tee log/backend.voxceleb2Naug_train_train_pytorch_tacotron2+spkemb_spkidonly_shufflebatching_bs128_spkloss_weight1_unsync.bestspkidacc.snapshot.ep.47.log
#### + nceloss exp/voxceleb2Naug_train_train_pytorch_tacotron2+spkemb_spkidonly_nceloss_shufflebatching_bs76_spkloss_weight1_nceloss_weight{0.03,0.1,1}_unsync
(TODO, current spklossbest) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_train_pytorch_tacotron2+spkemb_spkidonly_nceloss_shufflebatching_bs76_spkloss_weight1_nceloss_weight0.03_unsync 2>&1 | tee log/backend.voxceleb2Naug_train_train_pytorch_tacotron2+spkemb_spkidonly_nceloss_shufflebatching_bs76_spkloss_weight1_nceloss_weight0.03_unsync.spklossbest.log
(TODO, current spklossbest) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_train_pytorch_tacotron2+spkemb_spkidonly_nceloss_shufflebatching_bs76_spkloss_weight1_nceloss_weight0.1_unsync 2>&1 | tee log/backend.voxceleb2Naug_train_train_pytorch_tacotron2+spkemb_spkidonly_nceloss_shufflebatching_bs76_spkloss_weight1_nceloss_weight0.1_unsync.spklossbest.log
(TODO, current spklossbest) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_train_pytorch_tacotron2+spkemb_spkidonly_nceloss_shufflebatching_bs76_spkloss_weight1_nceloss_weight1_unsync 2>&1 | tee log/backend.voxceleb2Naug_train_train_pytorch_tacotron2+spkemb_spkidonly_nceloss_shufflebatching_bs76_spkloss_weight1_nceloss_weight1_unsync.spklossbest.log
### W/ voxceleb2
## SPKID + TTS
### W/ voxceleb2Naug
#### 1e-3 (for snapshot.ep: add +4 (since I resume from snapshot.ep.5 by mistake) from the first rows from the output of either showspk or showrecon)
(DONE: 2.27, current bestlossNspkidlossNspkidacc, snapshot.ep.10) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --model snapshot.ep.10 --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_spkloss_weight0.03_fullyunsync_cleanrecon 2>&1 | tee log/backend.voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_spkloss_weight0.03_fullyunsync_cleanrecon.bestlossNspkidlossNspkidacc.snapshot.ep.10.log
(DONE: 2.20, good in general + before sudden increase in losses, snapshot.ep.11) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --model snapshot.ep.11 --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_spkloss_weight0.03_fullyunsync_cleanrecon 2>&1 | tee log/backend.voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_spkloss_weight0.03_fullyunsync_cleanrecon.good+b4suddenincrease_INlosses.snapshot.ep.11.log
(DONE: 2.08, bestlossNspkidacc, snapshot.ep.19) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --model snapshot.ep.19 --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_spkloss_weight0.03_fullyunsync_cleanrecon 2>&1 | tee log/backend.voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_spkloss_weight0.03_fullyunsync_cleanrecon.bestlossNspkidacc.snapshot.ep.19.log
(DONE: 2.02, bestspkidloss, snapshot.ep.20) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --model snapshot.ep.20 --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_spkloss_weight0.03_fullyunsync_cleanrecon 2>&1 | tee log/backend.voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_spkloss_weight0.03_fullyunsync_cleanrecon.bestspkidloss.snapshot.ep.20.log
(DONE: 2.00, bestl1loss, snapshot.ep.23) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --model snapshot.ep.23 --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_spkloss_weight0.03_fullyunsync_cleanrecon 2>&1 | tee log/backend.voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_spkloss_weight0.03_fullyunsync_cleanrecon.bestl1loss.snapshot.ep.23.log
(DONE: 2.05, bestmseloss, snapshot.ep.18) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --model snapshot.ep.18 --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_spkloss_weight0.03_fullyunsync_cleanrecon 2>&1 | tee log/backend.voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_spkloss_weight0.03_fullyunsync_cleanrecon.bestmseloss.snapshot.ep.18.log
#### 1e-4 (for snapshot.ep: add +10 (since I resume from snapshot.ep.11) from the first rows from the output of either showspk or showrecon)
(DONE: 2.08, bestlossNspkidlossNl1loss, snapshot.ep.17) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --model snapshot.ep.17 --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_lr1e-4_spkloss_weight0.03_fullyunsync_cleanrecon/ 2>&1 | tee log/backend.voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_lr1e-4_spkloss_weight0.03_fullyunsync_cleanrecon.bestlossNspkidlossNl1loss.snapshot.ep.17.log
(DONE: 2.06, bestspkidacc, snapshot.ep.18) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --model snapshot.ep.18 --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_lr1e-4_spkloss_weight0.03_fullyunsync_cleanrecon/ 2>&1 | tee log/backend.voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_lr1e-4_spkloss_weight0.03_fullyunsync_cleanrecon.bestspkidacc.snapshot.ep.18.log
(DONE: 1.95, bestmseloss, snapshot.ep.27) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --model snapshot.ep.27 --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_lr1e-4_spkloss_weight0.03_fullyunsync_cleanrecon/ 2>&1 | tee log/backend.voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_lr1e-4_spkloss_weight0.03_fullyunsync_cleanrecon.bestmseloss.snapshot.ep.27.log
##### + initopt (add +10 to idx)
(DONE: 2.05, bestlossNspkidlossNspkidacc, snapshot.ep.15) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --model snapshot.ep.15 --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_lr1e-4_initopt_spkloss_weight0.03_fullyunsync_cleanrecon/ 2>&1 | tee log/backend.voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_lr1e-4_initopt_spkloss_weight0.03_fullyunsync_cleanrecon.bestlossNspkidlossNspkidacc.snapshot.ep.15.log
(DONE: 2.02, bestreconlosses, snapshot.ep.19) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --model snapshot.ep.19 --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_lr1e-4_initopt_spkloss_weight0.03_fullyunsync_cleanrecon/ 2>&1 | tee log/backend.voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_lr1e-4_initopt_spkloss_weight0.03_fullyunsync_cleanrecon.bestlossNspkidlossNspkidacc.snapshot.ep.19.log
(DONE: 2.04, bestlossNmseloss, snapshot.ep.21) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --model snapshot.ep.21 --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_lr1e-4_initopt_spkloss_weight0.03_fullyunsync_cleanrecon/ 2>&1 | tee log/backend.voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_lr1e-4_initopt_spkloss_weight0.03_fullyunsync_cleanrecon.bestlossNspkidlossNspkidacc.snapshot.ep.21.log
(DONE: 2.00, bestl1loss, snapshot.ep.29) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --model snapshot.ep.29 --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_lr1e-4_initopt_spkloss_weight0.03_fullyunsync_cleanrecon/ 2>&1 | tee log/backend.voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_lr1e-4_initopt_spkloss_weight0.03_fullyunsync_cleanrecon.bestl1loss.snapshot.ep.29.log
#### 1e-5
##### from 1e-4_initopt snapshot.ep.12
(TODO, bestmseloss, snapshot.ep.25) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --model snapshot.ep.25 --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_lr1e-5_initopt_spkloss_weight0.03_fullyunsync_cleanrecon/ 2>&1 | tee log/backend.voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_lr1e-5_initopt_spkloss_weight0.03_fullyunsync_cleanrecon.bestmseloss.ep.25.log
##### from 1e-4_initopt snapshot.ep.21
(TODO, bestreconlosses, snapshot.ep.28) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --model snapshot.ep.28 --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_lr1e-5_initopt_fromep21_spkloss_weight0.03_fullyunsync_cleanrecon/ 2>&1 | tee log/backend.voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_lr1e-5_initopt_fromep21_spkloss_weight0.03_fullyunsync_cleanrecon.bestreconlosses.ep.28.log

## SPKID + TTS + NCE: Correct fix
### W/ voxceleb2Naug (for snapshot.ep: add +4 (since I resume from snapshot.ep.5 by mistake from the first rows from the output of either showspk or showrecon)
(DONE: 2.13, bestloss, snapshot.ep.8) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --model snapshot.ep.8 --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_cleanrecon_bs56_spkloss_weight0.03_nceloss_weight0.001_fullyunsync_cleanrecon/ 2>&1 | tee log/backend.voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_cleanrecon_bs56_spkloss_weight0.03_nceloss_weight0.001_fullyunsync_cleanrecon.bestloss.snapshot.ep.8.log
(DONE: 2.18, bestspkidlossNspkidacc, snapshot.ep.9) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --model snapshot.ep.9 --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_cleanrecon_bs56_spkloss_weight0.03_nceloss_weight0.001_fullyunsync_cleanrecon/ 2>&1 | tee log/backend.voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_cleanrecon_bs56_spkloss_weight0.03_nceloss_weight0.001_fullyunsync_cleanrecon.bestspkidlossNspkidacc.snapshot.ep.9.log
(DONE: 2.02, bestreconlosses, snapshot.ep.12) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --model snapshot.ep.12 --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_cleanrecon_bs56_spkloss_weight0.03_nceloss_weight0.001_fullyunsync_cleanrecon/ 2>&1 | tee log/backend.voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_cleanrecon_bs56_spkloss_weight0.03_nceloss_weight0.001_fullyunsync_cleanrecon.bestreconlosses.snapshot.ep.12.log
### 1e-4 in lr (resuming from ep.12) + initopt
#### (expdir name changed by "mv exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_cleanrecon_bs56_lr1e-4_initopt_spkloss_weight0.03_nceloss_weight0.001_fullyunsync_cleanrecon/ exp/voxceleb2Naug_train_pytorch_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_bs56_lr1e-4_initopt_spkloss_weight0.03_nceloss_weight0.001/")
(DONE: 1.95, bestlossNspkidlossNspkidacc, snapshot.ep.22) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --model snapshot.ep.22 --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_pytorch_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_bs56_lr1e-4_initopt_spkloss_weight0.03_nceloss_weight0.001 2>&1 | tee log/backend.voxceleb2Naug_train_pytorch_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_cleanrecon_bs56_lr1e-4_initopt_spkloss_weight0.03_nceloss_weight0.001_fullyunsync_cleanrecon.bestlossNspkidlossNspkidacc.snapshot.ep.22.log
(DONE: 1.92, bestreconlosses, snapshot.ep.28) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --model snapshot.ep.28 --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_pytorch_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_bs56_lr1e-4_initopt_spkloss_weight0.03_nceloss_weight0.001 2>&1 | tee log/backend.voxceleb2Naug_train_pytorch_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_cleanrecon_bs56_lr1e-4_initopt_spkloss_weight0.03_nceloss_weight0.001_fullyunsync_cleanrecon.bestreconlosses.snapshot.ep.28.log

## Very early epochs (run by mistake)
### W/ voxceleb2Naug
(DONE: 19.43, current bestlossNspkidlossNspkidacc, snapshot.ep.3) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --model snapshot.ep.3 --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_spkloss_weight0.03_fullyunsync_cleanrecon 2>&1 | tee log/backend.voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_cleanrecon_spkloss_weight0.03_fullyunsync_cleanrecon.bestlossNspkidlossNspkidacc.snapshot.ep.3.log
## SPKID + TTS + NCE: Correct fix
(DONE: 2.67, current bestlossNspkidlossNspkidacc, snapshot.ep.2) bash run_backendonly_cpuparallel.voxceleb2Naugplda_voxceleb1eval.sh --model snapshot.ep.2 --nj 70 --ngpu 0 --expdir exp/voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_cleanrecon_bs56_spkloss_weight0.03_nceloss_weight0.001_fullyunsync_cleanrecon/ 2>&1 | tee log/backend.voxceleb2Naug_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_cleanrecon_bs56_spkloss_weight0.03_nceloss_weight0.001_fullyunsync_cleanrecon.bestlossNspkidlossNspkidacc.snapshot.ep.2.log


# 4. Check results
expdir=''
paste <(valloss ${expdir}/results/log | sort -nk3) <(valspkloss ${expdir}/results/log | sort -nk3) <(valspkacc ${expdir}/results/log | sort -rnk3)
paste <(valloss ${expdir}/results/log | sort -nk3) <(vall1loss ${expdir}/results/log | sort -nk3) <(valmseloss ${expdir}/results/log | sort -nk3)


# -1. Debug
(ING) bash run.asrttsspkid.cleanrecon.debug.stage4.sh --gpu_ix $(free-gpu) --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_cleanrecon_bs10.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.001
