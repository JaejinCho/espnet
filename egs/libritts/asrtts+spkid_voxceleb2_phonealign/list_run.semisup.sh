# Outline: Running list of semi-supervised experiments

## example from list_run.sh
(DONE, spkloss_weight=0.03) bash run.asrttsspkid.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching.bs64.log

## semi-supervised
### 1. data prep (********** always specify labspk_num **********)
(DONE) bash run.asrttsspkid_semisup.sh --stage 0 --stop_stage 2 --n_average 0 --labspk_num 800 2>&1 | tee log/run.asrttsspkid_semisup.dataprep.tilstage2.log
### 2. Actual training
#### labspk_num 800
(DONE) bash run.asrttsspkid_semisup.sh --labspk_num 800 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_semi.bs64.log
##### ICASSP 2021 - start
###### semisup + nceloss (No upsampling of labeled data. Later if I want to balance the ratio between lab and nolab data sets, it would also be good to downsample nolab data dynamically)
####### labspk_num800 + nonlab 800spk
(ING) bash run.asrttsspkid_semisup_nceloss.800labspk_nolabspkIncrease.sh --labspk_num 800 --nolabspk_num 800 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_nceloss_semi_bs56_NOspklosswWeightingbyRatio.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_ncelossWspkembnorm_semi_lab800nonlab800_NOspklosswWeightingbyRatio.bs56.log
####### labspk_num800 + nonlab 1600spk
(ING) bash run.asrttsspkid_semisup_nceloss.800labspk_nolabspkIncrease.sh --labspk_num 800 --nolabspk_num 1600 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_nceloss_semi_bs56_NOspklosswWeightingbyRatio.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_ncelossWspkembnorm_semi_lab800nonlab1600_NOspklosswWeightingbyRatio.bs56.log
####### labspk_num800 + unlab rest
(ING) bash run.asrttsspkid_semisup_nceloss.sh --labspk_num 800 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_nceloss_semi_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_ncelossWspkembnorm_semi.bs56.log
####### change to lr=1e-4, self.it = 125000 (already self.lamb = 5)
(ING) bash run.asrttsspkid_semisup_nceloss.sh --labspk_num 800 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_nceloss_semi_bs56_lr1e-4.yaml --resume exp/voxceleb2_800spk_stack_lab_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_nceloss_semi_bs56_spkloss_weight0.03_fullyunsync/results/snapshot.ep.7 --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_ncelossWspkembnorm_semi.bs56.lr1e-3to1e-4.fromep7to30.log
####### NOspklosswWeightingbyRatio
(ING) bash run.asrttsspkid_semisup_nceloss.sh --labspk_num 800 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_nceloss_semi_bs56_NOspklosswWeightingbyRatio.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_ncelossWspkembnorm_semi_NOspklosswWeightingbyRatio.bs56.log
###### semisup (keep labspk 800 while increasing nolab spk)
####### nolab 800 (x1)
(DONE) bash run.asrttsspkid_semisup.800labspk_nolabspkIncrease.sh --labspk_num 800 --nolabspk_num 800 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi.yaml --stage 0 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_semi.labspknum800_nolabspknum800.bs64.log
######## change to lr=1e-4 (til ep45, self.it = 125000 (already self.lamb = 5))
(ING) bash run.asrttsspkid_semisup.800labspk_nolabspkIncrease.sh --labspk_num 800 --nolabspk_num 800 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_lr1e-4_ep45.yaml --resume exp/voxceleb2_800spk_stack_lab_train_800nolabspk_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_spkloss_weight0.03_fullyunsync/results/snapshot.ep.28 --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_semi.labspknum800_nolabspknum800.bs64.lr1e-3tolr1e-4.fromep28to45.log
######## change to lr=1e-4 and spkloss_w=0.003 (til ep45, self.it = 125000 (already self.lamb = 5))
(DONE) bash run.asrttsspkid_semisup.800labspk_nolabspkIncrease.sh --labspk_num 800 --nolabspk_num 800 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_lr1e-4_ep45.yaml --resume exp/voxceleb2_800spk_stack_lab_train_800nolabspk_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_spkloss_weight0.03_fullyunsync/results/snapshot.ep.28 --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.003 2>&1 | tee log/run.asrttsspkid.spkloss_weight0.03to0.003.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_semi.labspknum800_nolabspknum800.bs64.lr1e-3tolr1e-4.fromep28to45.log
####### nolab 1600 (x2)
(ING) bash run.asrttsspkid_semisup.800labspk_nolabspkIncrease.sh --labspk_num 800 --nolabspk_num 1600 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi.yaml --stage 0 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_semi.labspknum800_nolabspknum1600.bs64.log
######## change to lr=1e-4 and spkloss_w=0.003 (til ep45, self.it = 125000 (already self.lamb = 5))
(ING) bash run.asrttsspkid_semisup.800labspk_nolabspkIncrease.sh --labspk_num 800 --nolabspk_num 1600 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_lr1e-4_ep45.yaml --resume exp/voxceleb2_800spk_stack_lab_train_1600nolabspk_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_spkloss_weight0.03_fullyunsync/results/snapshot.ep.18 --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.003 2>&1 | tee log/run.asrttsspkid.spkloss_weight0.03to0.003.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_semi.labspknum800_nolabspknum1600.bs64.lr1e-3tolr1e-4.fromep18to30.log
####### (If possible) nolab 2400 (x3)
####### nolab 3200 (x4)
(ING) bash run.asrttsspkid_semisup.800labspk_nolabspkIncrease.sh --labspk_num 800 --nolabspk_num 3200 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi.yaml --stage 0 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_semi.labspknum800_nolabspknum3200.bs64.log
######## change to lr=1e-4 and spkloss_w=0.003, self.it = 125000 (already self.lamb = 5)
(ING) bash run.asrttsspkid_semisup.800labspk_nolabspkIncrease.sh --labspk_num 800 --nolabspk_num 3200 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_lr1e-4.yaml --resume exp/voxceleb2_800spk_stack_lab_train_3200nolabspk_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_spkloss_weight0.03_fullyunsync/results/snapshot.ep.9 --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.003 2>&1 | tee log/run.asrttsspkid.spkloss_weight0.003.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_semi.labspknum800_nolabspknum3200.bs64.lr1e-3tolr1e-4.fromep9to30.log
####### nolab 6400 (x8 max) --> nolab 5314 (max)

#### *** labspk_num 800 (voxceleb2) + nolabspk from libritts
(ING, Got some errors so I just fixed cursorily for now) bash run.asrttsspkid_semisup_labfromvox2_nolabfromlibritts.sh --labspk_num 800 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_labfromvox2_nolabfromlibritts.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_semi_labfromvox2_nolabfromlibritts.bs64.log

##### ICASSP 2021 - end
##### lr=1e-4
(ING RESUME with lr=1e-4 from ep.5, self.it=153400 (actual as 102800 but self.lamb = 5 already so no prob)) bash run.asrttsspkid_semisup.sh --resume exp/voxceleb2_800spk_stack_lab_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_spkloss_weight0.03_fullyunsync/results/snapshot.ep.5 --labspk_num 800 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_lr1e-4.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_semi.bs64.labspk_num800.from1e-3to1e-4.from_ep.5.log
(ING RESUME with lr=1e-4, spkloss_weight=0.01 from ep.5, self.it=153400 (actual as 102800 but self.lamb = 5 already so no prob)) bash run.asrttsspkid_semisup.sh --resume exp/voxceleb2_800spk_stack_lab_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_spkloss_weight0.03_fullyunsync/results/snapshot.ep.5 --labspk_num 800 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_lr1e-4.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.01 2>&1 | tee log/run.asrttsspkid.spkloss_weightfrom0.03to0.01.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_semi.bs64.labspk_num800.from1e-3to1e-4.from_ep.5.log
(ING RESUME with lr=1e-4, spkloss_weight=0.003 from ep.5, self.it=153400 (actual as 102800 but self.lamb = 5 already so no prob)) bash run.asrttsspkid_semisup.sh --resume exp/voxceleb2_800spk_stack_lab_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_spkloss_weight0.03_fullyunsync/results/snapshot.ep.5 --labspk_num 800 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_lr1e-4.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.003 2>&1 | tee log/run.asrttsspkid.spkloss_weightfrom0.03to0.003.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_semi.bs64.labspk_num800.from1e-3to1e-4.from_ep.5.log
##### lr=1e-5
(ING RESUME with lr=1e-5, spkloss_weight=0.003 from ep.5, self.it=153400 (actual as 102800 but self.lamb = 5 already so no prob)) bash run.asrttsspkid_semisup.sh --resume exp/voxceleb2_800spk_stack_lab_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_spkloss_weight0.03_fullyunsync/results/snapshot.ep.5 --labspk_num 800 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_lr1e-5.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.003 2>&1 | tee log/run.asrttsspkid.spkloss_weightfrom0.03to0.003.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_semi.bs64.labspk_num800.from1e-3to1e-5.from_ep.5.log
#### labspk_num 1600
(DONE) bash run.asrttsspkid_semisup.sh --labspk_num 1600 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi.yaml --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_semi.bs64.labspk_num1600.log
##### lr=1e-4
(ING RESUME with lr=1e-4 from ep.6, self.it=156200 (actual as 102800 but self.lamb = 5 already so no prob)) bash run.asrttsspkid_semisup.sh --resume exp/voxceleb2_1600spk_stack_lab_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_spkloss_weight0.03_fullyunsync/results/snapshot.ep.6 --labspk_num 1600 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_lr1e-4.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_semi.bs64.labspk_num1600.from1e-3to1e-4.from_ep.6.log
(ING RESUME with lr=1e-4, spkloss_weight=0.01 from ep.6, self.it=156200 (actual as 102800 but self.lamb = 5 already so no prob)) bash run.asrttsspkid_semisup.sh --resume exp/voxceleb2_1600spk_stack_lab_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_spkloss_weight0.03_fullyunsync/results/snapshot.ep.6 --labspk_num 1600 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_lr1e-4.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.01 2>&1 | tee log/run.asrttsspkid.spkloss_weightfrom0.03to0.01.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_semi.bs64.labspk_num1600.from1e-3to1e-4.from_ep.6.log
(ING RESUME with lr=1e-4, spkloss_weight=0.003 from ep.6, self.it=156200 (actual as 102800 but self.lamb = 5 already so no prob)) bash run.asrttsspkid_semisup.sh --resume exp/voxceleb2_1600spk_stack_lab_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_spkloss_weight0.03_fullyunsync/results/snapshot.ep.6 --labspk_num 1600 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_lr1e-4.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.003 2>&1 | tee log/run.asrttsspkid.spkloss_weightfrom0.03to0.003.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_semi.bs64.labspk_num1600.from1e-3to1e-4.from_ep.6.log
##### lr=1e-5
(ING RESUME with lr=1e-5, spkloss_weight=0.01 from ep.6, self.it=156200 (actual as 102800 but self.lamb = 5 already so no prob)) bash run.asrttsspkid_semisup.sh --resume exp/voxceleb2_1600spk_stack_lab_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_spkloss_weight0.03_fullyunsync/results/snapshot.ep.6 --labspk_num 1600 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_lr1e-5.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.01 2>&1 | tee log/run.asrttsspkid.spkloss_weightfrom0.03to0.01.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_semi.bs64.labspk_num1600.from1e-3to1e-5.from_ep.6.log
#### labspk_num 2400
(ING) bash run.asrttsspkid_semisup.sh --labspk_num 2400 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi.yaml --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_semi.bs64.labspk_num2400.log
#### labspk_num 3200
(DONE) bash run.asrttsspkid_semisup.sh --labspk_num 3200 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi.yaml --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_semi.bs64.labspk_num3200log
(ING RESUME from ep.6, self.it=102800) bash run.asrttsspkid_semisup.sh --resume exp/voxceleb2_3200spk_stack_lab_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_spkloss_weight0.03_fullyunsync/results/snapshot.ep.6 --labspk_num 3200 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_lr1e-4.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_semi.bs64.labspk_num3200.from1e-3to1e-4.from_ep.6.log
#### labspk_num 4000
(DONE) bash run.asrttsspkid_semisup.sh --labspk_num 4000 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi.yaml --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_semi.bs64.labspk_num4000.log
(ING RESUME from ep.10, self.it=170400 (actual as 102800 but self.lamb = 5 already so no prob)) bash run.asrttsspkid_semisup.sh --resume exp/voxceleb2_4000spk_stack_lab_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_spkloss_weight0.03_fullyunsync/results/snapshot.ep.10 --labspk_num 4000 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_semi_lr1e-4.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching_semi.bs64.labspk_num4000.from1e-3to1e-4.from_ep.10.log

## non-semi but with smaller-amount-than-whole-voxceleb2 training
### 800 spk
(DONE) bash run.asrttsspkid_sup.sh --labspk_num 800 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching.bs64.labspk800.log
#### extend to 60 epochs with lr=1e-4 (self.it = 61000. already self.lamb=5)
(ING) bash run.asrttsspkid_sup.sh --resume exp/voxceleb2_800spk_stack_lab_train_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_spkloss_weight0.03_fullyunsync/results/snapshot.ep.28 --labspk_num 800 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_lr1e-4_ep60.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching.bs64.labspk800.tolr1e-4_ep60.log
### 2400 spk
(ING) bash run.asrttsspkid_sup.sh --labspk_num 2400 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight0.03.onlystage4.2flstm512Nusecat.fullyunsync.shufflebatching.bs64.labspk2400.log

## debug
bash run.asrttsspkid_semisup_nceloss.debug.sh --gpu_ix $(free-gpu) --labspk_num 800 --spkloss_weight 0.03 --stage 4 --stop_stage 4 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_nceloss_semi.yaml
