# *** actually run code was little diff.: means I changed the run code to be consistent after actual run so the expname and relevant parts' naming could be different
mkdir log

# 0. Features extracted using espnet make_fbank.sh are in /export/b18/jcho/espnet3/egs/libritts/tts_featext





# 1. Training
## 1) Tacotron2
(*** only for the first run ***) bash run.asrttsspkid.spkloss_weight.new.update.rf3.sh --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.spkloss_weight0.log
(DONE) bash run.asrttsspkid.spkloss_weight.new.update.rf3.sh --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.spkloss_weight0.03.onlystage4.log
(DONE, envcheck) bash run.asrttsspkid.spkloss_weight.new.update.rf3.sh --tag envcheck --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.spkloss_weight0.03.onlystage4.envcheck.log
(ING for spkloss is calculated correctly when resuming training) bash run.asrttsspkid.spkloss_weight.new.update.rf3.sh --train_config conf/train_pytorch_tacotron2+spkemb_noatt_rf3_epoch60.yaml --resume exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03/results/snapshot.ep.26 --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.spkloss_weight0.03.onlystage4.ep26to60.fromlossbest.log
## unsync experiments
### 200 to 400 random chunks
#### spkloss_weight 0.03
(DONE) bash run.asrttsspkid.spkloss_weight.new.update.rf3.unsync.sh --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.unsync.spkloss_weight0.03.onlystage4.log
(DONE, check the original script according to the result from this run) bash run.asrttsspkid.spkloss_weight.new.update.rf3.unsync.tempfix.sh --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.unsync.tempfix.spkloss_weight0.03.onlystage4.log
##### + specaug
(DONE) bash run.asrttsspkid.spkloss_weight.new.update.rf3.unsync.specaugtts.sh --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.unsync.specaugtts.spkloss_weight0.03.onlystage4.log
(DONE, run from ep.30 to ep.60) bash run.asrttsspkid.spkloss_weight.new.update.rf3.unsync.specaugtts.sh --train_config conf/train_pytorch_tacotron2+spkemb_noatt_rf3_epoch60.yaml --resume exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_specaug_spkloss_weight0.03_unsync/results/snapshot.ep.30 --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.unsync.specaugtts.spkloss_weight0.03.onlystage4.from30to60epochs.from_modellossbest_ep30.log
#### spkloss_weight 0
(DONE) bash run.asrttsspkid.spkloss_weight.new.update.rf3.unsync.sh --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.unsync.spkloss_weight0.onlystage4.log
##### + specaug
(DONE) bash run.asrttsspkid.spkloss_weight.new.update.rf3.unsync.specaugtts.sh --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.unsync.specaugtts.spkloss_weight0.onlystage4.log
(DONE, run from ep.30 to ep.60) bash run.asrttsspkid.spkloss_weight.new.update.rf3.unsync.specaugtts.sh --train_config conf/train_pytorch_tacotron2+spkemb_noatt_rf3_epoch60.yaml --resume exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_specaug_spkloss_weight0_unsync/results/snapshot.ep.30 --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.unsync.specaugtts.spkloss_weight0.onlystage4.from30to60epochs.from_modellossbest_ep30.log
### fixed chunk_len (200 and 400)
#### spkloss_weight 0.03
(DONE) bash run.asrttsspkid.spkloss_weight.new.update.rf3.unsync.fixedchunk.sh --chunk_len 200 --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.unsync_chunklen200.spkloss_weight0.03.onlystage4.log
(DONE) bash run.asrttsspkid.spkloss_weight.new.update.rf3.unsync.fixedchunk.sh --chunk_len 400 --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.unsync_chunklen400.spkloss_weight0.03.onlystage4.log

## fully unsync. *** Refer to coding_progress.txt for how I edited codes
### Newly generated codes (most of them are edited from some codes):
### - run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.sh
#### Spkloss_weight 0.03
(DONE) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.sh --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.onlystage4.log
(DONE (bs 60), w/ nce_loss 1) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_tacotron2+spkemb_noatt_rf3_nceloss_bs60.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 1 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight1.onlystage4.bs60.log
(STOP OOM, w/ nce_loss 0.3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.3 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.3.onlystage4.log
(DONE (bs 56), w/ nce_loss 0.1) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_tacotron2+spkemb_noatt_rf3_nceloss_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.1 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.1.onlystage4.bs56.log
(DONE (bs 48), w/ nce_loss 0.03) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_tacotron2+spkemb_noatt_rf3_nceloss_bs48.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.03.onlystage4.bs48.log
(DONE (bs 60), w/ nce_loss 0.03) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_tacotron2+spkemb_noatt_rf3_nceloss_bs60.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.03.onlystage4.bs60.log # to check if a jerk would NOT appear anymore that I saw in bs48 (the one above)
(DONE (bs 52), w/ nce_loss 0.01) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_tacotron2+spkemb_noatt_rf3_nceloss_bs52.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.01 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.01.onlystage4.bs52.log
(DONE (bs 52) from ep30 to 60, w/ nce_loss 0.01) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_tacotron2+spkemb_noatt_rf3_nceloss_bs52_ep60.yaml --resume exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs52_spkloss_weight0.03_nceloss_weight0.01_fullyunsync/results/snapshot.ep.30 --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.01 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.01.onlystage4.bs52.fromep30to60.log
(DONE (bs 60), w/ nce_loss 0.01) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_tacotron2+spkemb_noatt_rf3_nceloss_bs60.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.01 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.01.onlystage4.bs60.log
(STOP OOM (bs 60, shufflebathcing), w/ nce_loss 0.01) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_tacotron2+spkemb_noatt_rf3_nceloss_bs60_shufflebatching.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.01 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.01.onlystage4.bs60_shufflebatching.log
(ING (bs 56, shufflebathcing), w/ nce_loss 0.01) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_tacotron2+spkemb_noatt_rf3_nceloss_bs56_shufflebatching.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.01 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.01.onlystage4.bs56_shufflebatching.log
(DONE (bs 60), w/ nce_loss 0.003) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_tacotron2+spkemb_noatt_rf3_nceloss_bs60.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.003 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.003.onlystage4.bs60.log
(DONE (bs 60), w/ nce_loss 0.001) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_tacotron2+spkemb_noatt_rf3_nceloss_bs60.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.001.onlystage4.bs60.log
(DONE, run from ep.30 to ep.50) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.sh --train_config conf/train_pytorch_tacotron2+spkemb_noatt_rf3_epoch50.yaml --resume exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_fullyunsync/results/snapshot.ep.30 --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.onlystage4.from30to50epochs.from_modellossbest_ep30.log
#### Spkloss_weight 0
(DONE) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.sh --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.onlystage4.log
##### (+) nceloss
(DONE, actually run code was little diff. (bs 60), w/ spkloss 0 + nceloss 0.01) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_tacotron2+spkemb_noatt_rf3_nceloss_bs60.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 --nceloss_weight 0.01 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.nceloss_weight0.01.onlystage4.bs60.log
(DONE (bs 60), w/ nce_loss 0.003) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_tacotron2+spkemb_noatt_rf3_nceloss_bs60.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 --nceloss_weight 0.003 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.nceloss_weight0.003.onlystage4.bs60.log
(DONE (bs 60), w/ nce_loss 0.001) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_tacotron2+spkemb_noatt_rf3_nceloss_bs60.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.nceloss_weight0.001.onlystage4.bs60.log
### + specaug (directly to 60 epochs)
(DONE) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.specaugtts.sh --train_config conf/train_pytorch_tacotron2+spkemb_noatt_rf3_epoch60.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.specaugtts.spkloss_weight0.onlystage4.log
(DONE (bs 60), w/ nce_loss + specaug, 0.003) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_tacotron2+spkemb_noatt_rf3_nceloss_specaug_bs60.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.003 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.003.onlystage4.bs60.specaug.log
(DONE (bs 56, bs60 CUDA OOM), w/ nce_loss + specaug + shufflebatching, 0.003) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_tacotron2+spkemb_noatt_rf3_nceloss_specaug_bs56_shufflebatching.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.003 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.003.onlystage4.bs56_shufflebatching.specaug.log
### Transfer learning (to voxceleb1): They seemed fast in convergence
(ING) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.sh --tag transfer_from_voxceleb2x1 --resume /export/b18/jcho/espnet3/egs/libritts/asrtts+spkid_voxceleb2_kaldiasr_phonealign_rf3_pretrain_800spk/exp/voxceleb2_800spk_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_fullyunsync/results/model.loss.best --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.onlystage4.transfer_from_voxceleb2x1_spklossweight0.log
(ING) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.sh --tag transfer_from_libritts --resume /export/b18/jcho/espnet3/egs/libritts/asrtts+spkid_libris_kaldiasr_phonealign_rf3_fs16k/exp/train_train_16k_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_fullyunsync/results/model.loss.best --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.onlystage4.transfer_from_libritts_spklossweight0.log

## 2) Fastspeech (Non auto-regressive)
(ING, spkloss_weight=0) bash run.asrttsspkid.spkloss_weight.new.update.rf3.nonAR.sh --train_config conf/train_pytorch_fastspeech_speakerid_phnali.yaml --tag b4BatchsizeChecking --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.nonAR.spkloss_weight0.onlystage4.log
(ING, spkloss_weight=0.03) bash run.asrttsspkid.spkloss_weight.new.update.rf3.nonAR.sh --train_config conf/train_pytorch_fastspeech_speakerid_phnali.yaml --tag b4BatchsizeChecking --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.nonAR.spkloss_weight0.03.onlystage4.log

## 3) Forward tacotron2
### easy ones
#### spkloss_weight = 0
(DONE) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.onlystage4.forwardtacotron2.log
(DONE, 1flstm) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_1flstm.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.onlystage4.forwardtacotron2_1flstm.log
(DONE, 2flstm) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.onlystage4.forwardtacotron2_2flstm.log
(DONE, use_concate=true) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_usecat.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.onlystage4.forwardtacotron2_usecat.log
(DONE, 2flstm & use_concate=true) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstmNusecat.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.onlystage4.forwardtacotron2_2flstmNusecat.log
##### ICASSP 2021 (fullyunsync + shufflebatching) - start
###### (+) nce
####### (+) spkembnorm
(DONE, bs 56, w/ spkembnorm spkloss 0 + nceloss 0.01) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_spkembnorm_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 --nceloss_weight 0.01 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync_shufflebatching.spkembnorm.spkloss_weight0.nceloss_weight0.01.bs56.onlystage4.log
######## (+) am-margin in NCEloss
(DONE, bs 56, w/ spkembnorm spkloss 0 + nceloss 0.01, am_scaling=60, am_margin=0.2) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_spkembnorm_amsoftmaxINnceloss60N0.2_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 --nceloss_weight 0.01 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync_shufflebatching.spkembnorm.spkloss_weight0.nceloss_weight0.01.spkembnorm_amsoftmaxINnceloss60N0.2.bs56.onlystage4.log
(DONE, bs 56, w/ spkembnorm spkloss 0 + nceloss 0.01, am_scaling=60, am_margin=0.3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_spkembnorm_amsoftmaxINnceloss60N0.3_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 --nceloss_weight 0.01 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync_shufflebatching.spkembnorm.spkloss_weight0.nceloss_weight0.01.spkembnorm_amsoftmaxINnceloss60N0.3.bs56.onlystage4.log
(ING, bs 56, w/ spkembnorm spkloss 0 + nceloss 0.01, am_scaling=30, am_margin=0.1) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_spkembnorm_amsoftmaxINnceloss30N0.1_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 --nceloss_weight 0.01 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync_shufflebatching.spkembnorm.spkloss_weight0.nceloss_weight0.01.spkembnorm_amsoftmaxINnceloss30N0.1.bs56.onlystage4.log
(DONE, bs 56, w/ spkembnorm spkloss 0 + nceloss 0.01, am_scaling=30, am_margin=0.2) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_spkembnorm_amsoftmaxINnceloss30N0.2_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 --nceloss_weight 0.01 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync_shufflebatching.spkembnorm.spkloss_weight0.nceloss_weight0.01.spkembnorm_amsoftmaxINnceloss30N0.2.bs56.onlystage4.log
(DONE, bs 56, w/ spkembnorm spkloss 0 + nceloss 0.01, am_scaling=30, am_margin=0.3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_spkembnorm_amsoftmaxINnceloss30N0.3_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 --nceloss_weight 0.01 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync_shufflebatching.spkembnorm.spkloss_weight0.nceloss_weight0.01.spkembnorm_amsoftmaxINnceloss30N0.3.bs56.onlystage4.log
######## (+) am-margin (30N0.2, 0N0.2) and no-margin in NCEloss with different nceloss weight = {0.001,0.1,1}
######### nceloss_w=0.001
(ING, bs 56, w/ spkembnorm spkloss 0 + nceloss 0.001, am_scaling=30, am_margin=0.2) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_spkembnorm_amsoftmaxINnceloss30N0.2_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync_shufflebatching.spkembnorm.spkloss_weight0.nceloss_weight0.001.spkembnorm_amsoftmaxINnceloss30N0.2.bs56.onlystage4.log
######### nceloss_w=0.1
(DONE, bs 56, w/ spkembnorm spkloss 0 + nceloss 0.1) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_spkembnorm_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 --nceloss_weight 0.1 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync_shufflebatching.spkembnorm.spkloss_weight0.nceloss_weight0.1.bs56.onlystage4.log
(DONE, bs 56, w/ spkembnorm spkloss 0 + nceloss 0.1, am_scaling=30, am_margin=0.2) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_spkembnorm_amsoftmaxINnceloss30N0.2_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 --nceloss_weight 0.1 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync_shufflebatching.spkembnorm.spkloss_weight0.nceloss_weight0.1.spkembnorm_amsoftmaxINnceloss30N0.2.bs56.onlystage4.log
(DONE, bs 56, w/ spkembnorm spkloss 0 + nceloss 0.1, am_scaling=1, am_margin=0.2) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_spkembnorm_amsoftmaxINnceloss1N0.2_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 --nceloss_weight 0.1 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync_shufflebatching.spkembnorm.spkloss_weight0.nceloss_weight0.1.spkembnorm_amsoftmaxINnceloss1N0.2.bs56.onlystage4.log
######### nceloss_w=1
(STOPPED (NOT BETTER THAN 0.1), bs 56, w/ spkembnorm spkloss 0 + nceloss 1) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_spkembnorm_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 --nceloss_weight 1 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync_shufflebatching.spkembnorm.spkloss_weight0.nceloss_weight1.bs56.onlystage4.log
(DONE, bs 56, w/ spkembnorm spkloss 0 + nceloss 1, am_scaling=30, am_margin=0.2) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_spkembnorm_amsoftmaxINnceloss30N0.2_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 --nceloss_weight 1 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync_shufflebatching.spkembnorm.spkloss_weight0.nceloss_weight1.spkembnorm_amsoftmaxINnceloss30N0.2.bs56.onlystage4.log
(DONE, bs 56, w/ spkembnorm spkloss 0 + nceloss 1, am_scaling=1, am_margin=0.2) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_spkembnorm_amsoftmaxINnceloss1N0.2_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 --nceloss_weight 1 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync_shufflebatching.spkembnorm.spkloss_weight0.nceloss_weight1.spkembnorm_amsoftmaxINnceloss1N0.2.bs56.onlystage4.log
###### * Different architectures
(DONE, 2flstm1024 & use_concate=true) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm1024Nusecat_fullyunsync_shufflebatching.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.onlystage4.forwardtacotron2_2flstm1024Nusecat_shufflebatching_fullyunsync.log
(DONE, 2flstm2048 & use_concate=true) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm2048Nusecat_fullyunsync_shufflebatching.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.onlystage4.forwardtacotron2_2flstm2048Nusecat_shufflebatching_fullyunsync.log
(DONE, 3flstm512 & use_concate=true) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_3flstm512Nusecat_fullyunsync_shufflebatching.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.onlystage4.forwardtacotron2_3flstm512Nusecat_shufflebatching_fullyunsync.log
(DONE, 4flstm512 & use_concate=true) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_4flstm512Nusecat_fullyunsync_shufflebatching.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.onlystage4.forwardtacotron2_4flstm512Nusecat_shufflebatching_fullyunsync.log
####### Expand epochs (with or without lr decrease)
######## to 60ep (w/ lr1e-4)
(ING resuming w/ lr1e-4 to 60 ep (self.it=61000 (self.lamb=5 already)), 2flstm512 & use_concate=true) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --resume exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_spkloss_weight0/results/snapshot.ep.28 --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_lr1e-4_ep60.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.onlystage4.forwardtacotron2_2flstm512Nusecat_shufflebatching_fullyunsync.log
(ING resuming w/ lr1e-4 to 60 ep (self.it=61000 (self.lamb=5 already)), 2flstm1024 & use_concate=true) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --resume exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm1024Nusecat_fullyunsync_shufflebatching_spkloss_weight0/results/snapshot.ep.29 --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm1024Nusecat_fullyunsync_shufflebatching_lr1e-4_ep60.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.onlystage4.forwardtacotron2_2flstm1024Nusecat_shufflebatching_fullyunsync.log
(ING resuming w/ lr1e-4 to 60 ep (self.it=61000 (self.lamb=5 already)), 2flstm2048 & use_concate=true) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --resume exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm2048Nusecat_fullyunsync_shufflebatching_spkloss_weight0/results/snapshot.ep.29 --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm2048Nusecat_fullyunsync_shufflebatching_lr1e-4_ep60.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.onlystage4.forwardtacotron2_2flstm2048Nusecat_shufflebatching_fullyunsync.lr1e-4ep60.log
(ING resuming to 60 ep (self.it=61000 (self.lamb=5 already)), 2flstm2048 & use_concate=true) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --resume exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm2048Nusecat_fullyunsync_shufflebatching_spkloss_weight0/results/snapshot.ep.29 --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm2048Nusecat_fullyunsync_shufflebatching_ep60.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.onlystage4.forwardtacotron2_2flstm2048Nusecat_shufflebatching_fullyunsync.toep60.log
######## to 75ep (w/ lr1e-5): One without setting self.it=61000 (was set to 0) were moved to exp/deprecated and running them again with the proper setting
(ING resuming w/ lr1e-5 to 80 ep (self.it=61000 (self.lamb=5 already)), 2flstm512 & use_concate=true) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --resume exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_lr1e-4_ep60_spkloss_weight0/results/snapshot.ep.58 --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_lr1e-5_ep75.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.onlystage4.forwardtacotron2_2flstm512Nusecat_shufflebatching_lr1e-4_ep60_fullyunsync.tolr1e-5ep75.log
(ING resuming w/ lr1e-5 to 80 ep (self.it=61000 (self.lamb=5 already)), 2flstm1024 & use_concate=true) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --resume exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm1024Nusecat_fullyunsync_shufflebatching_lr1e-4_ep60_spkloss_weight0/results/snapshot.ep.58 --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm1024Nusecat_fullyunsync_shufflebatching_lr1e-5_ep75.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.onlystage4.forwardtacotron2_2flstm1024Nusecat_shufflebatching_lr1e-4_ep60_fullyunsync.tolr1e-5ep75.log
(ING resuming w/ lr1e-5 to 80 ep (self.it=61000 (self.lamb=5 already)), 2flstm2048 & use_concate=true) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --resume exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm2048Nusecat_fullyunsync_shufflebatching_lr1e-4_ep60_spkloss_weight0/results/snapshot.ep.57 --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm2048Nusecat_fullyunsync_shufflebatching_lr1e-5_ep75.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.onlystage4.forwardtacotron2_2flstm2048Nusecat_shufflebatching_lr1e-4_ep60_fullyunsync.tolr1e-5ep75.log
######## (TODO) to 100ep
##### ICASSP 2021 (fullyunsync + shufflebatching) - end
#### spkloss_weight = 0.03
(DONE) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.03.onlystage4.forwardtacotron2.log
(DONE, 2flstm512 fullyunsync w/ spkloss_weight=0.03) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512_fullyunsync.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.03.onlystage4.forwardtacotron2_2flstm512_fullyunsync.log
(DONE, 1flstm fullyunsync w/ spkloss_weight=0.03) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_1flstm_fullyunsync.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.03.onlystage4.forwardtacotron2_1flstm_fullyunsync.log
(DONE, gru) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_gru.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.03.onlystage4.forwardtacotron2.decodergru.log
(DONE, gru) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_gru.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.onlystage4.forwardtacotron2.decodergru.log
#### "2flstm512 & use_concate=true" with different sampling methods
(DONE, 2flstm512 & use_concate=true) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.onlystage4.forwardtacotron2_2flstm512Nusecat.log
(ING for ICASSP 2021, w/ proper self.it setting, 2flstm512 & use_concate=true) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --resume /export/b18/jcho/espnet3/egs/libritts/asrtts+spkid_voxceleb1_kaldiasr_phonealign_rf3/exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_spkloss_weight0/results/snapshot.ep.29 --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_lr1e-4_ep60.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.onlystage4.forwardtacotron2_2flstm512Nusecat.from29epto60.lr1e-3to1e-4.log
(DONE, unsync 2flstm512 & use_concate=true) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_unsync.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.onlystage4.forwardtacotron2_2flstm512Nusecat_unsync.log
(ING for ICASSP 2021, w/ proper self.it setting, unsync 2flstm512 & use_concate=true) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --resume exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_unsync_spkloss_weight0/results/snapshot.ep.29 --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_unsync_lr1e-4_ep60.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.onlystage4.forwardtacotron2_2flstm512Nusecat_unsync.from29epto60.lr1e-3to1e-4.log
(DONE, fullyunsync 2flstm512 & use_concate=true) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_fullyunsync.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.onlystage4.forwardtacotron2_2flstm512Nusecat_fullyunsync.log
(DONE, fixed bs w/ shuf. fullyunsync 2flstm512 & use_concate=true) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_fullyunsync_shufflebatching.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.onlystage4.forwardtacotron2_2flstm512Nusecat_fullyunsync_shufflebatching.log
(DONE, fullyunsync 2flstm512 & use_concate=true) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_fullyunsync.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.03.onlystage4.forwardtacotron2_2flstm512Nusecat_fullyunsync.log
(DONE for ICASSP 2021, unsync 2flstm512 & use_concate=true) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_unsync.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.03.onlystage4.forwardtacotron2_2flstm512Nusecat_unsync.log
(DONE for ICASSP 2021, fullutt 2flstm512 & use_concate=true) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.03.onlystage4.forwardtacotron2_2flstm512Nusecat.log
(DONE, fixed bs w/ shuf. fullyunsync 2flstm512 & use_concate=true) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_fullyunsync_shufflebatching.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.03.onlystage4.forwardtacotron2_2flstm512Nusecat_fullyunsync_shufflebatching.log
#### Increase a network size from "2flstm512 & use_concate=true"
(DONE, fixed bs w/ shuf. fullyunsync 2flstm1024 & use_concate=true) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm1024Nusecat_fullyunsync_shufflebatching.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.03.onlystage4.forwardtacotron2_2flstm1024Nusecat_fullyunsync_shufflebatching.log
(DONE, fixed bs w/ shuf. fullyunsync 3flstm512 & use_concate=true) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_3flstm512Nusecat_fullyunsync_shufflebatching.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.03.onlystage4.forwardtacotron2_3flstm512Nusecat_fullyunsync_shufflebatching.log
(DONE, fixed bs w/ shuf. fullyunsync 3flstm1024 & use_concate=true) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_3flstm1024Nusecat_fullyunsync_shufflebatching.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.03.onlystage4.forwardtacotron2_3flstm1024Nusecat_fullyunsync_shufflebatching.log
#### (+4 nceloss)
(DONE (bs56. idk but bs64 n bs60 OOM), FT2 w/ nce_loss + shufflebatching, nceloss_weight=0.001, lr=2e-3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_lr2times_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.001.onlystage4.FT2_2flstm512Nusecat.shufflebatching.lr2times.bs56.log
(DONE, FT2 w/ nce_loss + shufflebatching, nceloss_weight=0.001, lr=1.5e-3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_lr1andhalftimes_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.001.onlystage4.FT2_2flstm512Nusecat.shufflebatching.lr1.5times.bs56.log
(DONE, FT2 w/ nce_loss + shufflebatching, nceloss_weight=0.001, lr=1e-3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.001.onlystage4.FT2_2flstm512Nusecat.shufflebatching.bs56.log
(DONE ***THE FIX WAS WRONG*** for check after fix (sorting parts: ilens_chunk, indices = torch.sort(ilens_chunk,descending=True) && xs_4ys_4phnali = xs_4ys_4phnali[indices] in /export/b18/jcho/espnet3/espnet/nets/pytorch_backend/e2e_tts_forwardtacotron2_speakerid_update_fullyunsync_nce.py), FT2 w/ nce_loss + shufflebatching, nceloss_weight=0.001, lr=1e-3)
bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --tag checkafterfix --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.001.onlystage4.FT2_2flstm512Nusecat.shufflebatching.bs56.checkafterfix.log
(ING, for check after refix. This fix is NOT needed for ones W/O nceloss (sorting parts: ilens_chunk, indices = torch.sort(ilens_chunk,descending=True) && xs_4ys_4phnali = xs_4ys_4phnali[indices] in /export/b18/jcho/espnet3/espnet/nets/pytorch_backend/e2e_tts_forwardtacotron2_speakerid_update_fullyunsync_nce.py), FT2 w/ nce_loss + shufflebatching, nceloss_weight=0.001, lr=1e-3)
bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --tag checkafterrefix --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.001.onlystage4.FT2_2flstm512Nusecat.shufflebatching.bs56.checkafterrefix.log
##### (+5 Transfer) - start (TODO): ********************** Must add "transfer" when moving the expdirs below once training runs are done. Also, add below "--tag transfer_from_lossbest" **************************
(ING, transfer to specaug, FT2 w/ nce_loss + shufflebatching, nceloss_weight=0.001, lr=1e-3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --tag transfer_from_lossbest --resume exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs56_spkloss_weight0.03_nceloss_weight0.001/results/model.loss.best --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_specaug_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.001.onlystage4.FT2_2flstm512Nusecat.shufflebatching.bs56.TransferLossbest2Specaug.log
(ING, transfer to specaugfix, FT2 w/ nce_loss + shufflebatching, nceloss_weight=0.001, lr=1e-3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --tag transfer_from_lossbest --resume exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs56_spkloss_weight0.03_nceloss_weight0.001/results/model.loss.best --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_specaugfix_bs40.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.001.onlystage4.FT2_2flstm512Nusecat.shufflebatching.bs56to40.TransferLossbest2Specaugfix.log
(ING, transfer to specaugfix2, FT2 w/ nce_loss + shufflebatching, nceloss_weight=0.001, lr=1e-3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --tag transfer_from_lossbest --resume exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs56_spkloss_weight0.03_nceloss_weight0.001/results/model.loss.best --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_specaugfix2_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.001.onlystage4.FT2_2flstm512Nusecat.shufflebatching.bs56.TransferLossbest2Specaugfix2.log
##### (+5 Transfer) - end
##### (+5 run to ep.60) - start
(DONE run from ep.30 (loss best model) to ep.60, FT2 w/ nce_loss + shufflebatching, nceloss_weight=0.001, lr=1e-3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --tag ep30to60 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_bs56_ep60.yaml --resume exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs56_spkloss_weight0.03_nceloss_weight0.001/results/snapshot.ep.30 --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.001.onlystage4.FT2_2flstm512Nusecat.shufflebatching.bs56.fromep30to60.log
(ING run from 1 to 60 epochs, FT2 w/ nce_loss + shufflebatching, nceloss_weight=0.001, lr=1e-3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --tag ep1to60 --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_bs56_ep60.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.001.onlystage4.FT2_2flstm512Nusecat.shufflebatching.bs56.fromep1to60.log
##### (+5 run to ep.60) - end
(DONE, FT2 w/ nce_loss + shufflebatching, nceloss_weight=0.0003, lr=1e-3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.0003 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.0003.onlystage4.FT2_2flstm512Nusecat.shufflebatching.bs56.log
(DONE, FT2 w/ nce_loss + shufflebatching, nceloss_weight=0.0001, lr=1e-3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.0001 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.0001.onlystage4.FT2_2flstm512Nusecat.shufflebatching.bs56.log
(DONE ttsonly (bs56. idk but bs64 n bs60 OOM), FT2 w/ nce_loss + shufflebatching, nceloss_weight=0.001, lr=2e-3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_lr2times_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.nceloss_weight0.001.onlystage4.FT2_2flstm512Nusecat.shufflebatching.lr2times.bs56.log
(DONE ttsonly (bs56. idk but bs64 n bs60 OOM), FT2 w/ nce_loss + shufflebatching, nceloss_weight=0.01, lr=2e-3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_lr2times_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 --nceloss_weight 0.01 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.nceloss_weight0.01.onlystage4.FT2_2flstm512Nusecat.shufflebatching.lr2times.bs56.log
(DONE ttsonly (bs56. idk but bs64 n bs60 OOM), FT2 w/ nce_loss + shufflebatching, nceloss_weight=0.1, lr=2e-3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_lr2times_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 --nceloss_weight 0.1 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.nceloss_weight0.1.onlystage4.FT2_2flstm512Nusecat.shufflebatching.lr2times.bs56.log
(DONE ttsonly (bs56. idk but bs64 n bs60 OOM), FT2 w/ nce_loss + shufflebatching, nceloss_weight=1, lr=2e-3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_lr2times_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 --nceloss_weight 1 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.nceloss_weight1.onlystage4.FT2_2flstm512Nusecat.shufflebatching.lr2times.bs56.log
##### (lr = 1e-3)
(ING ttsonly (bs56. idk but bs64 n bs60 OOM), FT2 w/ nce_loss + shufflebatching, nceloss_weight=0.0001, lr=1e-3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 --nceloss_weight 0.0001 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.nceloss_weight0.0001.onlystage4.FT2_2flstm512Nusecat.shufflebatching.bs56.log
(ING ttsonly (bs56. idk but bs64 n bs60 OOM), FT2 w/ nce_loss + shufflebatching, nceloss_weight=0.001, lr=1e-3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.nceloss_weight0.001.onlystage4.FT2_2flstm512Nusecat.shufflebatching.bs56.log
(ING ttsonly (bs56. idk but bs64 n bs60 OOM), FT2 w/ nce_loss + shufflebatching, nceloss_weight=0.01, lr=1e-3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 --nceloss_weight 0.01 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.nceloss_weight0.01.onlystage4.FT2_2flstm512Nusecat.shufflebatching.bs56.log
(ING ttsonly (bs56. idk but bs64 n bs60 OOM), FT2 w/ nce_loss + shufflebatching, nceloss_weight=0.1, lr=1e-3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 --nceloss_weight 0.1 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.nceloss_weight0.1.onlystage4.FT2_2flstm512Nusecat.shufflebatching.bs56.log
(ING ttsonly (bs56. idk but bs64 n bs60 OOM), FT2 w/ nce_loss + shufflebatching, nceloss_weight=1, lr=1e-3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 --nceloss_weight 1 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.nceloss_weight1.onlystage4.FT2_2flstm512Nusecat.shufflebatching.bs56.log
##### + specaug
(DONE (bs56. idk but bs64 n bs60 OOM), FT2 w/ nce_loss + specaug + shufflebatching, nceloss_weight=0.001, lr=2e-3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_lr2times_specaug_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.001.onlystage4.FT2_2flstm512Nusecat.shufflebatching.lr2times.specaug.bs56.log
(ING (bs56. idk but bs64 n bs60 OOM), FT2 w/ nce_loss + specaug + shufflebatching, nceloss_weight=0.001, lr=1e-3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_specaug_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.001.onlystage4.FT2_2flstm512Nusecat.shufflebatching.specaug.bs56.log
(STOP OOV (bs56. idk but bs64 n bs60 OOM), FT2 w/ nce_loss + specaugfix + shufflebatching, nceloss_weight=0.001, lr=1e-3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_specaugfix_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.001.onlystage4.FT2_2flstm512Nusecat.shufflebatching.specaugfix.bs56.log
(STOP OOV (bs52. idk but bs64 n bs60 OOM), FT2 w/ nce_loss + specaugfix + shufflebatching, nceloss_weight=0.001, lr=1e-3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_specaugfix_bs52.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.001.onlystage4.FT2_2flstm512Nusecat.shufflebatching.specaugfix.bs52.log
(STOP OOV (bs48. idk but bs64 n bs60 OOM), FT2 w/ nce_loss + specaugfix + shufflebatching, nceloss_weight=0.001, lr=1e-3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_specaugfix_bs48.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.001.onlystage4.FT2_2flstm512Nusecat.shufflebatching.specaugfix.bs48.log
(ING (bs44. idk but bs64 n bs60 OOM), FT2 w/ nce_loss + specaugfix + shufflebatching, nceloss_weight=0.001, lr=1e-3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_specaugfix_bs44.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.001.onlystage4.FT2_2flstm512Nusecat.shufflebatching.specaugfix.bs44.log
(ING (bs56. idk but bs64 n bs60 OOM), FT2 w/ nce_loss + specaugfix2 + shufflebatching, nceloss_weight=0.001, lr=1e-3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_specaugfix2_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.03.nceloss_weight0.001.onlystage4.FT2_2flstm512Nusecat.shufflebatching.specaugfix2.bs56.log
(DONE ttsonly (bs56. idk but bs64 n bs60 OOM), FT2 w/ nce_loss + specaug + shufflebatching, nceloss_weight=0.001, lr=2e-3) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_lr2times_specaug_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 --nceloss_weight 0.001 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.spkloss_weight0.nceloss_weight0.001.onlystage4.FT2_2flstm512Nusecat.shufflebatching.lr2times.specaug.bs56.log
### difficult ones
(ING) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_difficult.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.03.onlystage4.forwardtacotron2.difficult.log
(ING) bash run.asrttsspkid.spkloss_weight.new.update.rf1.forwardtacotron2.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_difficult.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.onlystage4.forwardtacotron2.difficult.log

## 4) light speech (forward tts)
(DONE, Really bad: NO backend eval) bash run.asrttsspkid.spkloss_weight.new.update.rf1.lightspeech.sh --train_config conf/train_pytorch_lightspeech+spkemb_noatt_rf1.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.03.onlystage4.lightspeech.log
(DONE, Really bad: NO backend eval) bash run.asrttsspkid.spkloss_weight.new.update.rf1.lightspeech.sh --train_config conf/train_pytorch_lightspeech+spkemb_noatt_rf1.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.onlystage4.lightspeech.log
(DONE) bash run.asrttsspkid.spkloss_weight.new.update.rf1.lightspeech.sh --train_config conf/train_pytorch_lightspeech+spkemb_noatt_rf1_lrsame.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.03.onlystage4.lightspeech.lrsame.log
(STOPPED: no need for more run, envcheck) bash run.asrttsspkid.spkloss_weight.new.update.rf1.lightspeech.sh --tag envcheck --train_config conf/train_pytorch_lightspeech+spkemb_noatt_rf1_lrsame.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.03.onlystage4.lightspeech.lrsame.envcheck.log
(DONE) bash run.asrttsspkid.spkloss_weight.new.update.rf1.lightspeech.sh --train_config conf/train_pytorch_lightspeech+spkemb_noatt_rf1_lrsame.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0 2>&1 | tee log/run.asrttsspkid.spkloss_weight.new.update.rf1.spkloss_weight0.onlystage4.lightspeech.lrsame.log





# 2. Backend training and evaluation
## full length training
### tacotron2
(DONE) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03.log
(ING, envcheck) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_envcheck_spkloss_weight0.03/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_envcheck_spkloss_weight0.03.log
(ING, envcheck)
(DONE) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --model snapshot.ep.16 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03.snapshot.ep.16.spklossNaccbest.log
### fastspeech
(DONE: 5.77, lossbest at snapshot.ep.50) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_fastspeech_speakerid_phnali_b4BatchsizeChecking_spkloss_weight0.03 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_fastspeech_speakerid_phnali_b4BatchsizeChecking_spkloss_weight0.03.log
(DONE: 12.46, lossbest at snapshot.ep.50) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_fastspeech_speakerid_phnali_b4BatchsizeChecking_spkloss_weight0 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_fastspeech_speakerid_phnali_b4BatchsizeChecking_spkloss_weight0.log
(DONE: 5.79, lossbest at snapshot.ep.100 after 400+ epochs) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_fastspeech_speakerid_phnali_b4BatchsizeChecking_spkloss_weight0.03 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_fastspeech_speakerid_phnali_b4BatchsizeChecking_spkloss_weight0.03.log
(DONE: 11.11, lossbest at snapshot.ep.100 after 400+ epochs) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_fastspeech_speakerid_phnali_b4BatchsizeChecking_spkloss_weight0 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_fastspeech_speakerid_phnali_b4BatchsizeChecking_spkloss_weight0.log
### forwardtacotron2
#### normal
(DONE) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_spkloss_weight0/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_spkloss_weight0.log
(DONE) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_spkloss_weight0.03/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_spkloss_weight0.03.log
#### ablation exps
(DONE, 2flstm) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm_spkloss_weight0/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm_spkloss_weight0.log
(DONE, use_concate=true) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_usecat_spkloss_weight0/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_usecat_spkloss_weight0.log
(DONE, 2flstm & use_concate=true) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstmNusecat_spkloss_weight0/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstmNusecat_spkloss_weight0.log
(DONE, 2flstm512 & use_concate=true) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_spkloss_weight0/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_spkloss_weight0.log
(ING for ICASSP 2021, 2flstm512 & use_concate=true, finallossbest) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_spkloss_weight0.03/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_spkloss_weight0.03.finallossbest.ep.25.log
(DONE: 5.31 for ICASSP 2021, 2flstm512 & use_concate=true) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --model snapshot.ep.60 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_lr1e-4_ep60_spkloss_weight0/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_lr1e-4_ep60_spkloss_weight0.finallossbest.ep.60.log
(DONE, 2flstm512) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512_spkloss_weight0/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512_spkloss_weight0.log
(DONE, 1flstm) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_1flstm_spkloss_weight0/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_1flstm_spkloss_weight0.log
#### difficult
(DONE) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_difficult_spkloss_weight0/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_difficult_spkloss_weight0.log
(DONE) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_difficult_spkloss_weight0.03/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_difficult_spkloss_weight0.03.log
(DONE, gru) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_gru_spkloss_weight0/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_gru_spkloss_weight0.log
(DONE, gru) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_gru_spkloss_weight0.03/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_gru_spkloss_weight0.03.log
### lightspeech
(DONE) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_lightspeech+spkemb_noatt_rf1_lrsame_spkloss_weight0/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_lightspeech+spkemb_noatt_rf1_lrsame_spkloss_weight0.log
(DONE) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_lightspeech+spkemb_noatt_rf1_lrsame_spkloss_weight0.03/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_lightspeech+spkemb_noatt_rf1_lrsame_spkloss_weight0.03.log

## chunk training
### 200 to 400 random chunks
#### spkloss_weight 0.03
##### unsync
(DONE, best validation/main/loss) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync.log
(DONE, tempfix for checking zeropadding differently) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync_tempfix/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync_tempfix.log
(DONE, best validation/main/spkid_loss) bash run_backendonly_cpuparallel.voxceleb1.sh --model snapshot.ep.30 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync.snapshot.ep.30.spkid_lossNaccbest.log
(DONE, 2flstm512 & use_concate=true) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_unsync_spkloss_weight0/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_unsync_spkloss_weight0.log
(ING for ICASSP 2021, 2flstm512 & use_concate=true, finalreconlossbest) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --model snapshot.ep.60 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_unsync_lr1e-4_ep60_spkloss_weight0 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_unsync_lr1e-4_ep60_spkloss_weight0.finallossbest.ep.60.log
####### (+ specaug)
(DONE, best validation/main/loss, ep.30) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_specaug_spkloss_weight0.03_unsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_specaug_spkloss_weight0.03_unsync.log
(DONE, latest one (since others are all similar in loss), ep.60) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --model snapshot.ep.60 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_epoch60_specaug_spkloss_weight0.03_unsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_epoch60_specaug_spkloss_weight0.03_unsync.snapshot.ep.60.log
(ING, bestspkid_{acc,loss}, ep.52) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --model snapshot.ep.52 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_epoch60_specaug_spkloss_weight0.03_unsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_epoch60_specaug_spkloss_weight0.03_unsync.snapshot.ep.52.bestspkid_accNloss.log
##### fullyunsync
(DONE, best for validation/main/{loss,spkid_loss,spkid_acc}, ep.30) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_fullyunsync.log
(DONE, best loss after 50 epochs, ep.31) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_epoch50_spkloss_weight0.03_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_epoch50_spkloss_weight0.03_fullyunsync.log
(DONE, best spkid_acc after 50 epochs, ep.43) bash run_backendonly_cpuparallel.voxceleb1.sh --model snapshot.ep.43 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_epoch50_spkloss_weight0.03_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_epoch50_spkloss_weight0.03_fullyunsync.snapshot.ep.43.spkid_accbest.log
(DONE, best spkid_loss after 50 epochs, ep.34) bash run_backendonly_cpuparallel.voxceleb1.sh --model snapshot.ep.34 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_epoch50_spkloss_weight0.03_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_epoch50_spkloss_weight0.03_fullyunsync.snapshot.ep.34.spkid_lossbest.log
(DONE, 2nd best spkid_loss after 50 epochs, ep.50) bash run_backendonly_cpuparallel.voxceleb1.sh --model snapshot.ep.50 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_epoch50_spkloss_weight0.03_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_epoch50_spkloss_weight0.03_fullyunsync.snapshot.ep.50.spkid_loss2ndbest.log
(DONE, 2flstm512 & use_concate=true) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_fullyunsync_spkloss_weight0.03/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_fullyunsync_spkloss_weight0.03.log
(ING for ICASSP 2021, 2flstm512 & use_concate=true) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --model snapshot.ep.21 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_unsync_spkloss_weight0.03/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_unsync_spkloss_weight0.03.finallossbest.ep.21.log
(ING, 2flstm512) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512_fullyunsync_spkloss_weight0.03/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512_fullyunsync_spkloss_weight0.03.log
(ING, 1flstm) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_1flstm_fullyunsync_spkloss_weight0.03/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_1flstm_fullyunsync_spkloss_weight0.03.log
###### (+ shuffle batching)
(DONE: 3.54 (alllossesbest as ep.28), 2flstm512 & use_concate=true) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_spkloss_weight0.03 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_spkloss_weight0.03.log
###### var lda_dim
(ING)
for lda_dim in 150 200 250 300 350 400;do
    (bash run_backendonly_cpuparallel.varlda_dim.voxceleb1.sh --lda_dim ${lda_dim} --stage 6 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_spkloss_weight0.03 2>&1 | tee log/backend.lda_dim${lda_dim}.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_spkloss_weight0.03.alllossesbest.log) &
done
(DONE: 3.44 (ep.29), 2flstm512 & use_concate=true) bash run_backendonly_cpuparallel.voxceleb1.sh --model snapshot.ep.29 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_spkloss_weight0.03 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_spkloss_weight0.03.ep.29.log
(DONE: 3.49 (ep.30), 2flstm512 & use_concate=true) bash run_backendonly_cpuparallel.voxceleb1.sh --model snapshot.ep.30 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_spkloss_weight0.03 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_spkloss_weight0.03.ep.30.log
#### Increase a network size from "2flstm512 & use_concate=true"
##### 2flstm1024
(DONE: 3.56, lossbestAmong30) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm1024Nusecat_fullyunsync_shufflebatching_spkloss_weight0.03 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm1024Nusecat_fullyunsync_shufflebatching_spkloss_weight0.03.log
###### var lda_dim
(DONE: 3.44 best with lda_dim=300)
for lda_dim in 150 200 250 300 350 400;do
    (bash run_backendonly_cpuparallel.varlda_dim.voxceleb1.sh --lda_dim ${lda_dim} --stage 6 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm1024Nusecat_fullyunsync_shufflebatching_spkloss_weight0.03 2>&1 | tee log/backend.lda_dim${lda_dim}.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm1024Nusecat_fullyunsync_shufflebatching_spkloss_weight0.03.lossbestAmong30.log) &
done
##### 3flstm512
(ING, lossbestAmong30) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_3flstm512Nusecat_fullyunsync_shufflebatching_spkloss_weight0.03 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_3flstm512Nusecat_fullyunsync_shufflebatching_spkloss_weight0.03.log
##### 3flstm1024
(ING, lossbestAmong30) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_3flstm1024Nusecat_fullyunsync_shufflebatching_spkloss_weight0.03 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_3flstm1024Nusecat_fullyunsync_shufflebatching_spkloss_weight0.03.log
####### In below two, the expdir names are changed ones from the original (due to too long name error in qsub)
(DONE, 2flstm512 & use_concate=true, lr2times + shufflebatching, nceloss=0.001, bs56) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_lr2times_bs56_spkloss_weight0.03_nceloss_weight0.001/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_lr2times_bs56_spkloss0.03_nceloss0.001.log
(DONE, 2flstm512 & use_concate=true, lr1andhalf + shufflebatching, nceloss=0.001, bs56) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_lr1andhalf_bs56_spkloss_weight0.03_nceloss_weight0.001/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_lr1andhalf_bs56_spkloss0.03_nceloss0.001.log
(ING spkid_acc best, 2flstm512 & use_concate=true, lr1andhalf + shufflebatching, nceloss=0.001, bs56) bash run_backendonly_cpuparallel.voxceleb1.sh --model snapshot.ep.29 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_lr1andhalf_bs56_spkloss_weight0.03_nceloss_weight0.001/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_lr1andhalf_bs56_spkloss0.03_nceloss0.001.snapshot.ep.29.spkid_accbest.log
(ING spkid_loss best, 2flstm512 & use_concate=true, lr1andhalf + shufflebatching, nceloss=0.001, bs56) bash run_backendonly_cpuparallel.voxceleb1.sh --model snapshot.ep.4 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_lr1andhalf_bs56_spkloss_weight0.03_nceloss_weight0.001/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_lr1andhalf_bs56_spkloss0.03_nceloss0.001.snapshot.ep.4.spkid_lossbest.log
(DONE, 2flstm512 & use_concate=true, lr1 + shufflebatching, nceloss=0.001, bs56) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs56_spkloss_weight0.03_nceloss_weight0.001/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs56_spkloss0.03_nceloss0.001.log
(DONE spkid_acc best, 2flstm512 & use_concate=true, lr1 + shufflebatching, nceloss=0.001, bs56) bash run_backendonly_cpuparallel.voxceleb1.sh --model snapshot.ep.19 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs56_spkloss_weight0.03_nceloss_weight0.001/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs56_spkloss0.03_nceloss0.001.snapshot.ep.19.spkid_accbest.log
(DONE spkid_loss best, 2flstm512 & use_concate=true, lr1 + shufflebatching, nceloss=0.001, bs56) bash run_backendonly_cpuparallel.voxceleb1.sh --model snapshot.ep.5 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs56_spkloss_weight0.03_nceloss_weight0.001/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs56_spkloss0.03_nceloss0.001.snapshot.ep.5.spkid_lossbest.log
(DONE checkafterfix, 2flstm512 & use_concate=true, lr1 + shufflebatching, nceloss=0.001, bs56) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs56_checkafterfix_spkloss_weight0.03_nceloss_weight0.001/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs56_checkafterfix_spkloss0.03_nceloss0.001.log
(DONE: 3.49 checkafterrefix lossNreconlossesbest (ep.30 from graph), 2flstm512 & use_concate=true, lr1 + shufflebatching, nceloss=0.001, bs56) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs56_checkafterrefix_spkloss_weight0.03_nceloss_weight0.001/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs56_checkafterrefix_spkloss0.03_nceloss0.001.log
(DONE: 3.45 checkafterrefix spkidaccbest (ep.28), 2flstm512 & use_concate=true, lr1 + shufflebatching, nceloss=0.001, bs56) bash run_backendonly_cpuparallel.voxceleb1.sh --model snapshot.ep.28 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs56_checkafterrefix_spkloss_weight0.03_nceloss_weight0.001/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs56_checkafterrefix_spkloss0.03_nceloss0.001.spkaccbest.snapshot.ep.28.log
(DONE: 3.49, checkafterrefix spkidlossbest (ep.24), 2flstm512 & use_concate=true, lr1 + shufflebatching, nceloss=0.001, bs56) bash run_backendonly_cpuparallel.voxceleb1.sh --model snapshot.ep.24 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs56_checkafterrefix_spkloss_weight0.03_nceloss_weight0.001/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs56_checkafterrefix_spkloss0.03_nceloss0.001.spkidlossbest.snapshot.ep.24.log
(DONE, transfer2specaug + 2flstm512 & use_concate=true, lr1 + shufflebatching, nceloss=0.001, bs56) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs56_spkloss_weight0.03_nceloss_weight0.001_transfer2specaug/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs56_spkloss0.03_nceloss0.001_transfer2specaug.log
(ING, transfer2specaugfix + 2flstm512 & use_concate=true, lr1 + shufflebatching, nceloss=0.001, bs40) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs40_spkloss_weight0.03_nceloss_weight0.001_transfer2specaugfix/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs40_spkloss0.03_nceloss0.001_transfer2specaugfix.log
(DONE, transfer2specaugfix2 + 2flstm512 & use_concate=true, lr1 + shufflebatching, nceloss=0.001, bs56) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs56_spkloss_weight0.03_nceloss_weight0.001_transfer2specaugfix2/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs56_spkloss0.03_nceloss0.001_transfer2specaugfix2.log
(ING, 2flstm512 & use_concate=true, lr1 + shufflebatching, nceloss=0.0003, bs56) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs56_spkloss_weight0.03_nceloss_weight0.0003/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs56_spkloss0.03_nceloss0.0003.log
(ING, 2flstm512 & use_concate=true, lr1 + shufflebatching, nceloss=0.0001, bs56) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs56_spkloss_weight0.03_nceloss_weight0.0001/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs56_spkloss0.03_nceloss0.0001.log
###### (+ nceloss)
(DONE, nceloss_weight=0.01, lossbest, ep.15) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs52_spkloss_weight0.03_nceloss_weight0.01_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs52_spkloss_weight0.03_nceloss_weight0.01_fullyunsync.lossbest.log
(DONE, nceloss_weight=0.01, spkid_lossbest, ep.29) bash run_backendonly_cpuparallel.voxceleb1.sh --model snapshot.ep.29 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs52_spkloss_weight0.03_nceloss_weight0.01_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs52_spkloss_weight0.03_nceloss_weight0.01_fullyunsync.snapshot.ep.29.spkid_lossbest.log
(ING, nceloss_weight=0.01, lossbest) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs52_ep60_spkloss_weight0.03_nceloss_weight0.01_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs52_ep60_spkloss_weight0.03_nceloss_weight0.01_fullyunsync.snapshot.lossbest.log
(ING, nceloss_weight=0.01, lossbest) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs60_spkloss_weight0.03_nceloss_weight0.01_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs60_spkloss_weight0.03_nceloss_weight0.01_fullyunsync.snapshot.lossbest.log
(ING, nceloss_weight=0.01 + shufflebatching, lossbest) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_nceloss_bs60_shufflebatching_spkloss_weight0.03_nceloss_weight0.01_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs60_shufflebatching_spkloss_weight0.03_nceloss_weight0.01_fullyunsync.snapshot.lossbest.log
(ING, nceloss_weight=0.01 + shufflebatching, lossbest) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_nceloss_bs56_shufflebatching_spkloss_weight0.03_nceloss_weight0.01_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs56_shufflebatching_spkloss_weight0.03_nceloss_weight0.01_fullyunsync.snapshot.lossbest.log
(ING, nceloss_weight=0.003, lossbest) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs60_spkloss_weight0.03_nceloss_weight0.003_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs60_spkloss_weight0.03_nceloss_weight0.003_fullyunsync.snapshot.lossbest.log
(DONE, nceloss_weight=0.001, lossbest) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs60_spkloss_weight0.03_nceloss_weight0.001_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs60_spkloss_weight0.03_nceloss_weight0.001_fullyunsync.snapshot.lossbest.log
(DONE, nceloss_weight=0.03, lossbest) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs48_spkloss_weight0.03_nceloss_weight0.03_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs48_spkloss_weight0.03_nceloss_weight0.03_fullyunsync.lossbest.log
(ING, nceloss_weight=0.03, lossbest) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_nceloss_bs60_spkloss_weight0.03_nceloss_weight0.03_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_nceloss_bs60_spkloss_weight0.03_nceloss_weight0.03_fullyunsync.lossbest.log
(DONE, nceloss_weight=0.1, lossbest) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs56_spkloss_weight0.03_nceloss_weight0.1_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs56_spkloss_weight0.03_nceloss_weight0.1_fullyunsync.lossbest.log
(DONE, nceloss_weight=1, lossbest) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs60_spkloss_weight0.03_nceloss_weight1_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs60_spkloss_weight0.03_nceloss_weight1_fullyunsync.lossbest.log
####### (+7 specaug)
(DONE, + specaug, nceloss_weight=0.003, lossbest) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_nceloss_specaug_bs60_spkloss_weight0.03_nceloss_weight0.003_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs60_spkloss_weight0.03_nceloss_weight0.003_specaug_fullyunsync.snapshot.lossbest.log
(DONE, + specaug + shufflebatching nceloss_weight=0.003, lossbest) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_nceloss_specaug_bs56_shufflebatching_spkloss_weight0.03_nceloss_weight0.003_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs56_shufflebatching_spkloss_weight0.03_nceloss_weight0.003_fullyunsync.snapshot.lossbest.log
######## (+8 2flstm512Nusecat)
(DONE, 2flstm512 & use_concate=true, lr2times + shufflebatching + specaug, nceloss=0.001, bs56) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_specaug_lr2times_bs56_spkloss_weight0.03_nceloss_weight0.001/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_specaug_lr2times_bs56_spkloss0.03_nceloss0.001.log
(DONE, 2flstm512 & use_concate=true, shufflebatching + specaug, nceloss=0.001, bs56) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_specaug_bs56_spkloss_weight0.03_nceloss_weight0.001/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_specaug_bs56_spkloss0.03_nceloss0.001.log
(ING, 2flstm512 & use_concate=true, shufflebatching + specaugfix, nceloss=0.001, bs40) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_specaugfix_bs40_spkloss_weight0.03_nceloss_weight0.001/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_specaugfix_bs40_spkloss0.03_nceloss0.001.log
(DONE, 2flstm512 & use_concate=true, shufflebatching + specaugfix2, nceloss=0.001, bs56) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_specaugfix2_bs56_spkloss_weight0.03_nceloss_weight0.001/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_fullyunsync_shufflebatching_specaugfix2_bs56_spkloss0.03_nceloss0.001.log

###### Transfer learning (to voxceleb1): They seemed fast in convergence
(ING, best loss, ep.13) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_transfer_from_voxceleb2x1_spkloss_weight0.03_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_fullyunsync.transfer_from_voxceleb2x1.bestloss.log
(ING, best loss, ep.19) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_transfer_from_libritts_spkloss_weight0.03_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_fullyunsync.transfer_from_libritts.bestloss.log

#### spkloss_weight 0
##### unsync
(DONE) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_unsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_unsync.log
###### (+ specaug)
(DONE, best validation/main/loss, ep.30) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_specaug_spkloss_weight0_unsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_specaug_spkloss_weight0_unsync.log
(DONE, best validation/main/loss, ep.47) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_epoch60_specaug_spkloss_weight0_unsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_specaug_spkloss_weight0_unsync.snapshot.ep.47.lossbest.log
(DONE, best validation/main/loss, CHECKED: same as the one above) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --model snapshot.ep.47 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_epoch60_specaug_spkloss_weight0_unsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_specaug_spkloss_weight0_unsync.snapshot.ep.47.lossbest.check.log
(DONE, for the later epoch similar to best loss, ep.56) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --model snapshot.ep.56 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_epoch60_specaug_spkloss_weight0_unsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_specaug_spkloss_weight0_unsync.snapshot.ep.56.LaterEpochSimilartolossbest.check.log
##### fullyunsync
(DONE) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_fullyunsync.log
(DONE, 2flstm512 & use_concate=true) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_fullyunsync_spkloss_weight0/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_fullyunsync_spkloss_weight0.log
###### (+6 nceloss)
####### (+7 lr=1e-3 (default))
(DONE, nceloss_weight=0.01, lossbest) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs60_spkloss_weight0_nceloss_weight0.01_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs60_spkloss_weight0_nceloss_weight0.01_fullyunsync.snapshot.lossbest.log
(DONE, nceloss_weight=0.003, lossbest) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs60_spkloss_weight0_nceloss_weight0.003_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs60_spkloss_weight0_nceloss_weight0.003_fullyunsync.snapshot.lossbest.log
(DONE, nceloss_weight=0.001, lossbest) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs60_spkloss_weight0_nceloss_weight0.001_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_bs60_spkloss_weight0_nceloss_weight0.001_fullyunsync.snapshot.lossbest.log
######## (+8 w/ shufflebatching)
(ING, shufflebatching, nceloss_weight=1, lossbest) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_shufflebatching_bs56_spkloss_weight0_nceloss_weight1_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_shufflebatching_bs56_spkloss_weight0_nceloss_weight1_fullyunsync.lossbest.log
(ING, shufflebatching, nceloss_weight=0.1, lossbest) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_shufflebatching_bs56_spkloss_weight0_nceloss_weight0.1_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_shufflebatching_bs56_spkloss_weight0_nceloss_weight0.1_fullyunsync.lossbest.log
(ING, shufflebatching, nceloss_weight=0.01, lossbest) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_shufflebatching_bs56_spkloss_weight0_nceloss_weight0.01_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_shufflebatching_bs56_spkloss_weight0_nceloss_weight0.01_fullyunsync.lossbest.log
(ING, shufflebatching, nceloss_weight=0.001, lossbest) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_shufflebatching_bs56_spkloss_weight0_nceloss_weight0.001_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_shufflebatching_bs56_spkloss_weight0_nceloss_weight0.001_fullyunsync.lossbest.log
(ING, shufflebatching, nceloss_weight=0.0001, lossbest) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_shufflebatching_bs56_spkloss_weight0_nceloss_weight0.0001_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_shufflebatching_bs56_spkloss_weight0_nceloss_weight0.0001_fullyunsync.lossbest.log
####### (+7 lr=2e-3 (twice of default lr) w/ shufflebatching)
(DONE, shufflebatching, nceloss_weight=0.001, lossbest) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_shufflebatching_lr2times_bs56_spkloss_weight0_nceloss_weight0.001_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_shufflebatching_lr2times_bs56_spkloss_weight0_nceloss_weight0.001_fullyunsync.lossbest.log
(DONE, shufflebatching, nceloss_weight=0.01, lossbest) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_shufflebatching_lr2times_bs56_spkloss_weight0_nceloss_weight0.01_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_shufflebatching_lr2times_bs56_spkloss_weight0_nceloss_weight0.01_fullyunsync.lossbest.log
(DONE, shufflebatching, nceloss_weight=0.1, lossbest) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_shufflebatching_lr2times_bs56_spkloss_weight0_nceloss_weight0.1_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_shufflebatching_lr2times_bs56_spkloss_weight0_nceloss_weight0.1_fullyunsync.lossbest.log
(DONE, shufflebatching, nceloss_weight=1, lossbest) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_shufflebatching_lr2times_bs56_spkloss_weight0_nceloss_weight1_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_shufflebatching_lr2times_bs56_spkloss_weight0_nceloss_weight1_fullyunsync.lossbest.log
###### (+ specaug)
(DONE (straight training to ep60, took 2.63 days/227454 seconds), best validation/main/loss, ep.60) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_epoch60_specaug_spkloss_weight0_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_specaug_spkloss_weight0_fullyunsync.snapshot.ep.60.lossbest.log
(ING, shufflebatching, nceloss_weight=0.001, lossbest) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_lr2times_specaug_bs56_spkloss_weight0_nceloss_weight0.001_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_bs60_spkloss_weight0_nceloss_weight0.001_fullyunsync_shufflebatching_lr2times_specaug_bs56.snapshot.lossbest.log
###### (+ shuffle batching)
(DONE: 5.36, 2flstm512 & use_concate=true) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_spkloss_weight0 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_spkloss_weight0.log
##### from different training set for speaker embedding extractor
(ING, libritts) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir /export/b18/jcho/espnet3/egs/libritts/asrtts+spkid_libris_kaldiasr_phonealign_rf3_fs16k/exp/train_train_16k_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_fullyunsync.embext_libritts.log
(DONE, voxceleb2_1x) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir /export/b18/jcho/espnet3/egs/libritts/asrtts+spkid_voxceleb2_kaldiasr_phonealign_rf3_pretrain_800spk/exp/voxceleb2_800spk_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_fullyunsync.embext_voxceleb2_1x.log
(ING, voxceleb2_2x) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir /export/b18/jcho/espnet3/egs/libritts/asrtts+spkid_voxceleb2_kaldiasr_phonealign_rf3_pretrain_1600spk/exp/voxceleb2_1600spk_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_fullyunsync.embext_voxceleb2_2x.log
(ING, voxceleb2_3x) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir /export/b18/jcho/espnet3/egs/libritts/asrtts+spkid_voxceleb2_kaldiasr_phonealign_rf3_pretrain_2400spk/exp/voxceleb2_2400spk_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_fullyunsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_fullyunsync.embext_voxceleb2_3x.log

### fixed chunk_len (200/400)
#### spkloss_weight 0.03
##### 200
(DONE, best loss (also best spkid_acc), ep.26) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync_chunklen200/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_unsync_chunklen200.log # "validation/main/loss": 0.797301155225984, "validation/main/spkid_loss": 0.6057421535028723, "validation/main/spkid_acc": 0.981366738505747
(DONE, best spkid_loss, ep.28) bash run_backendonly_cpuparallel.voxceleb1.sh --model snapshot.ep.28 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync_chunklen200/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_unsync_chunklen200.snapshot.ep.28.spkid_lossbest.log # "validation/main/loss": 0.7998854446000067, "validation/main/spkid_loss": 0.6027245539047852, "validation/main/spkid_acc": 0.9804238505747125
(DONE, best spkid_loss, ep.28) bash run_backendonly_cpuparallel.voxceleb1.sh --model snapshot.ep.28 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync_chunklen200/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_unsync_chunklen200.snapshot.ep.28.spkid_lossbest.log # "validation/main/loss": 0.7998854446000067, "validation/main/spkid_loss": 0.6027245539047852, "validation/main/spkid_acc": 0.9804238505747125
##### 400
(DONE, best loss, ep.26) bash run_backendonly_cpuparallel.voxceleb1.sh --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync_chunklen400/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_unsync_chunklen400.log # validation/main/loss": 0.7911819111684273, validation/main/spkid_loss": 0.39276824531683313, validation/main/spkid_acc": 0.9897501026272577
(DONE, best spkid_loss, ep.29) bash run_backendonly_cpuparallel.voxceleb1.sh --model snapshot.ep.29 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync_chunklen400/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_unsync_chunklen400.snapshot.ep.29.spkid_lossbest.log # "validation/main/loss": 0.7922088208383528, "validation/main/spkid_loss": 0.3753188442687729, "validation/main/spkid_acc": 0.9904235940065681
(DONE, best spkid_acc, ep.24) bash run_backendonly_cpuparallel.voxceleb1.sh --model snapshot.ep.24 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync_chunklen400/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_unsync_chunklen400.snapshot.ep.24.spkid_lossbest.log # "validation/main/loss": 0.7958425054776257, "validation/main/spkid_loss": 0.4215573406164085, "validation/main/spkid_acc": 0.9906288485221674



# 2. (+) Backend evaluation with short utterances (5s, 3s, and 1s): spkloss_weight 0 and 0.03
## generate the data dir for those short utterances
bash gen_short_utterances.sh 2>&1 | tee log/gen_short_utterances.log
## run back-end evaluation only (******* SPKID ONLY ******* did NOT run here due to some path problems so did run them on /export/b18/jcho/espnet3/egs/libritts/asrtts+spkid)
## ******* fullshort exp.s should be run after shortshort exp.s are run *******
## shortshort config. (short enrollment utterances & short test chunks)
### seg 500
#### with TTS + SPKID
##### utt-wise training
(DONE) bash run_backendonly_cpuparallel.voxceleb1.shortshort_evalonly.sh --eval_set voxceleb1_test_seg500 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03.seg500.shortshort.log
##### chunk-wise training (length from 200 to 400 frames)
(DONE) bash run_backendonly_cpuparallel.voxceleb1.shortshort_evalonly.sh --eval_set voxceleb1_test_seg500 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync.seg500.shortshort.log
##### chunk-wise training (fixed length 200)
(DONE) bash run_backendonly_cpuparallel.voxceleb1.shortshort_evalonly.sh --eval_set voxceleb1_test_seg500 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync_chunklen200/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync_chunklen200.seg500.log
#### with TTS only
##### utt-wise training
(DONE) bash run_backendonly_cpuparallel.voxceleb1.shortshort_evalonly.sh --eval_set voxceleb1_test_seg500 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.seg500.shortshort.log
##### chunk-wise training (length from 200 to 400 frames)
(DONE) bash run_backendonly_cpuparallel.voxceleb1.shortshort_evalonly.sh --eval_set voxceleb1_test_seg500 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_unsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_unsync.seg500.shortshort.log
### seg 300
#### with TTS + SPKID
##### utt-wise training
(DONE) bash run_backendonly_cpuparallel.voxceleb1.shortshort_evalonly.sh --eval_set voxceleb1_test_seg500_seg300 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03.seg300.shortshort.log
##### chunk-wise training (length from 200 to 400 frames)
(DONE) bash run_backendonly_cpuparallel.voxceleb1.shortshort_evalonly.sh --eval_set voxceleb1_test_seg500_seg300 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync.seg300.shortshort.log
##### chunk-wise training (fixed length 200)
(DONE) bash run_backendonly_cpuparallel.voxceleb1.shortshort_evalonly.sh --eval_set voxceleb1_test_seg500_seg300 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync_chunklen200/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync_chunklen200.seg300.log
#### with TTS only
##### utt-wise training
(DONE) bash run_backendonly_cpuparallel.voxceleb1.shortshort_evalonly.sh --eval_set voxceleb1_test_seg500_seg300 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.seg300.shortshort.log
##### chunk-wise training (length from 200 to 400 frames)
(DONE) bash run_backendonly_cpuparallel.voxceleb1.shortshort_evalonly.sh --eval_set voxceleb1_test_seg500_seg300 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_unsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_unsync.seg300.shortshort.log
### seg 100
#### with TTS + SPKID
##### utt-wise training
(DONE) bash run_backendonly_cpuparallel.voxceleb1.shortshort_evalonly.sh --eval_set voxceleb1_test_seg500_seg300_seg100 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03.seg100.shortshort.log
##### chunk-wise training (length from 200 to 400 frames)
(DONE) bash run_backendonly_cpuparallel.voxceleb1.shortshort_evalonly.sh --eval_set voxceleb1_test_seg500_seg300_seg100 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync.seg100.shortshort.log
##### chunk-wise training (fixed length 200)
(DONE) bash run_backendonly_cpuparallel.voxceleb1.shortshort_evalonly.sh --eval_set voxceleb1_test_seg500_seg300_seg100 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync_chunklen200/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync_chunklen200.seg100.log
#### with TTS only
##### utt-wise training
(DONE) bash run_backendonly_cpuparallel.voxceleb1.shortshort_evalonly.sh --eval_set voxceleb1_test_seg500_seg300_seg100 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.seg100.shortshort.log
##### chunk-wise training (length from 200 to 400 frames)
(DONE) bash run_backendonly_cpuparallel.voxceleb1.shortshort_evalonly.sh --eval_set voxceleb1_test_seg500_seg300_seg100 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_unsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_unsync.seg100.shortshort.log

## fullshort config. (full enrollment utterances & short test chunks)
### seg 500
#### TTS + SPKID
(DONE, utt-train) bash run_backendonly_cpuparallel.voxceleb1.fullshort_evalonly.sh --eval_set voxceleb1_test_seg500 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03.seg500.fullshort.log
(DONE, chunk-train) bash run_backendonly_cpuparallel.voxceleb1.fullshort_evalonly.sh --eval_set voxceleb1_test_seg500 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync.seg500.fullshort.log
#### TTS only
(DONE, utt-train) bash run_backendonly_cpuparallel.voxceleb1.fullshort_evalonly.sh --eval_set voxceleb1_test_seg500 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.seg500.fullshort.log
(DONE, chunk-train) bash run_backendonly_cpuparallel.voxceleb1.fullshort_evalonly.sh --eval_set voxceleb1_test_seg500 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_unsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_unsync.seg500.fullshort.log
### seg 300
#### TTS + SPKID
(DONE, utt-train) bash run_backendonly_cpuparallel.voxceleb1.fullshort_evalonly.sh --eval_set voxceleb1_test_seg500_seg300 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03.seg300.fullshort.log
(DONE, chunk-train) bash run_backendonly_cpuparallel.voxceleb1.fullshort_evalonly.sh --eval_set voxceleb1_test_seg500_seg300 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync.seg300.fullshort.log
#### TTS only
(DONE, utt-train) bash run_backendonly_cpuparallel.voxceleb1.fullshort_evalonly.sh --eval_set voxceleb1_test_seg500_seg300 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.seg300.fullshort.log
(DONE, chunk-train) bash run_backendonly_cpuparallel.voxceleb1.fullshort_evalonly.sh --eval_set voxceleb1_test_seg500_seg300 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_unsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_unsync.seg300.fullshort.log
### seg 100
#### TTS + SPKID
(DONE, utt-train) bash run_backendonly_cpuparallel.voxceleb1.fullshort_evalonly.sh --eval_set voxceleb1_test_seg500_seg300_seg100 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03.seg100.fullshort.log
(DONE, chunk-train) bash run_backendonly_cpuparallel.voxceleb1.fullshort_evalonly.sh --eval_set voxceleb1_test_seg500_seg300_seg100 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03_unsync.seg100.fullshort.log
#### TTS + only
(DONE, utt-train) bash run_backendonly_cpuparallel.voxceleb1.fullshort_evalonly.sh --eval_set voxceleb1_test_seg500_seg300_seg100 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.seg100.fullshort.log
(DONE, chunk-train) bash run_backendonly_cpuparallel.voxceleb1.fullshort_evalonly.sh --eval_set voxceleb1_test_seg500_seg300_seg100 --nj 70 --ngpu 0 --expdir exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_unsync/ 2>&1 | tee log/backend.voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_unsync.seg100.fullshort.log







## ***** Debug related *****
### Debug were run as the log below (To check why the embeddings extracted from a same utterance were different in the full utterance extraction case)
list_run.debug.emb.log
### Writing and running a fixing code to deal with the problem found right above (this scripts will be used in *evalonly* scripts)
python merge_fullNseg.py [full emb fname (in)] [seg emb fname (in)] [new combined merged emb (out)]

### I/O debugg
(qlogin session) qlogin -l mem_free=20G -l gpu=1 -l "hostname=b1[12345678]*|c0[1345678]*|c1[01]*" -q i.q -now no
#### ipdb
##### back-end
##### front-end
bash run.asrttsspkid.spkloss_weight.new.update.rf3.unsync.debug.stage4.sh --gpu_ix $(free-gpu) --stage 4 --stop_stage 4
bash run.asrttsspkid.spkloss_weight.new.update.rf3.unsync.specaugtts.debug.stage4.sh --gpu_ix $(free-gpu) --stage 4 --stop_stage 4
bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.debug.stage4.sh --gpu_ix $(free-gpu) --stage 4 --stop_stage 4
bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.debug.stage4.addnceloss.sh --gpu_ix $(free-gpu) --stage 4 --stop_stage 4 --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_spkembnorm_amsoftmax.yaml
(for non auto regressive) bash run.asrttsspkid.spkloss_weight.new.update.rf3.nonAR.debug.sh --train_config conf/train_pytorch_fastspeech_speakerid_phnali.yaml --gpu_ix $(free-gpu) --stage 4 --stop_stage 4
(for forwardtacotron2) bash run.asrttsspkid.spkloss_weight.new.update.rf3.debug.stage4.sh --train_config conf/train_pytorch_forwardtacotron2+spkemb_noatt_rf1.yaml --gpu_ix $(free-gpu) --stage 4 --stop_stage 4
(transfer) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.debug.stage4.sh --gpu_ix $(free-gpu) --resume exp/voxceleb1_train_filtered_train_pytorch_forwardtacotron2+spkemb_rf1_2flstm512Nusecat_fullyunsync_shufflebatching_bs56_spkloss_weight0.03_nceloss_weight0.001/results/model.loss.best --train_config conf/train_pytorch_forwardtacotron2+spkemb_2flstm512Nusecat_nceloss_fullyunsync_shufflebatching_bs56.yaml --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03 --nceloss_weight 0.001
(train from snapshot) bash run.asrttsspkid.spkloss_weight.new.update.rf3.debug.stage4.sh --gpu_ix $(free-gpu) --verbose 2 --train_config conf/train_pytorch_tacotron2+spkemb_noatt_rf3_epoch60.yaml --resume exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0.03/results/snapshot.ep.26 --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03
(train from snapshot (the model trained from different dataset) bash run.asrttsspkid.spkloss_weight.new.update.rf3.debug.stage4.sh --tag transfer_from_voxceleb2x1 --gpu_ix $(free-gpu) --verbose 2 --train_config conf/train_pytorch_tacotron2+spkemb_noatt_rf3_epoch60.yaml --resume /export/b18/jcho/espnet3/egs/libritts/asrtts+spkid_voxceleb2_kaldiasr_phonealign_rf3_pretrain_800spk/exp/voxceleb2_800spk_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_spkloss_weight0_fullyunsync/results/snapshot.ep.30 --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03
(train from snapshot with specaug and unsync) bash run.asrttsspkid.spkloss_weight.new.update.rf3.unsync.specaugtts.debug.stage4.sh --gpu_ix $(free-gpu) --verbose 2 --train_config conf/train_pytorch_tacotron2+spkemb_noatt_rf3_epoch60.yaml --resume exp/voxceleb1_train_filtered_train_pytorch_train_pytorch_tacotron2+spkemb_noatt_rf3_specaug_spkloss_weight0.03_unsync/results/snapshot.ep.30 --stage 4 --stop_stage 4 --ngpu 1 --n_average 0 --spkloss_weight 0.03
#### print out info during runs
(for non auto regressive) bash run.asrttsspkid.spkloss_weight.new.update.rf3.nonAR.debug.sh --train_config conf/train_pytorch_fastspeech_speakerid_phnali_debug_byprintout.yaml --gpu_ix $(free-gpu) --stage 4 --stop_stage 4
#### py-spy
bash run.asrttsspkid.spkloss_weight.new.update.rf3.unsync.debug.stage4.pyspy.sh --gpu_ix $(free-gpu) --stage 4 --stop_stage 4
(for non auto regressive) bash run.asrttsspkid.spkloss_weight.new.update.rf3.nonAR.debug.pyspy.sh --train_config conf/train_pytorch_fastspeech_speakerid_phnali.yaml --gpu_ix $(free-gpu) --stage 4 --stop_stage 4
#### (NOT USING PERFECTLY AT THIS MOMENT) pytorch profiling: uncomment one of two commented lines above the line "CUDA_VISIBLE_DEVICES=${gpu_ix} tts_train_speakerid.py \" at stage 4
(for non auto regressive) bash run.asrttsspkid.spkloss_weight.new.update.rf3.nonAR.pytorchprofiling.sh --gpu_ix $(free-gpu) --stage 4 --stop_stage 4
#### stop at an error
(******* I think it is great in many cases (e.g., when you got some error after a few iterations, you do not need to run the iterations yourself manually). new way of decoding, do not set break points but will stop at the error while ipdb is still on. You have to enter "c" in the beginning) bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.newdebug.stage4.sh --train_config [config.yaml that must include model-module argument] --gpu_ix $(free-gpu) --stage 4 --stop_stage 4
bash run.asrttsspkid.spkloss_weight.new.update.rf3.fullyunsync.addnceloss.newdebug.sh --gpu_ix $(free-gpu) --stage 4 --stop_stage 4 --spkloss_weight 0.03 --nceloss_weight 0.01 --n_average 0
