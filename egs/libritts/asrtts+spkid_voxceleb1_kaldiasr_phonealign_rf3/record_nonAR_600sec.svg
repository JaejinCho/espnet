<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg version="1.1" width="1200" height="454" onload="init(evt)" viewBox="0 0 1200 454" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><!--Flame graph stack visualization. See https://github.com/brendangregg/FlameGraph for latest version, and http://www.brendangregg.com/flamegraphs.html for examples.--><!--NOTES: --><defs><linearGradient id="background" y1="0" y2="1" x1="0" x2="0"><stop stop-color="#eeeeee" offset="5%"/><stop stop-color="#eeeeb0" offset="95%"/></linearGradient></defs><style type="text/css">
text { font-family:"Verdana"; font-size:12px; fill:rgb(0,0,0); }
#title { text-anchor:middle; font-size:17px; }
#search { opacity:0.1; cursor:pointer; }
#search:hover, #search.show { opacity:1; }
#subtitle { text-anchor:middle; font-color:rgb(160,160,160); }
#unzoom { cursor:pointer; }
#frames > *:hover { stroke:black; stroke-width:0.5; cursor:pointer; }
.hide { display:none; }
.parent { opacity:0.5; }
</style><script type="text/ecmascript"><![CDATA[var nametype = 'Function:';
var fontsize = 12;
var fontwidth = 0.59;
var xpad = 10;
var inverted = true;
var searchcolor = 'rgb(230,0,230)';
var fluiddrawing = true;
var truncate_text_right = false;]]><![CDATA["use strict";
var details, searchbtn, unzoombtn, matchedtxt, svg, searching, frames;
function init(evt) {
    details = document.getElementById("details").firstChild;
    searchbtn = document.getElementById("search");
    unzoombtn = document.getElementById("unzoom");
    matchedtxt = document.getElementById("matched");
    svg = document.getElementsByTagName("svg")[0];
    frames = document.getElementById("frames");
    searching = 0;

    // Use GET parameters to restore a flamegraph's state.
    var restore_state = function() {
        var params = get_params();
        if (params.x && params.y)
            zoom(find_group(document.querySelector('[x="' + params.x + '"][y="' + params.y + '"]')));
        if (params.s)
            search(params.s);
    };

    if (fluiddrawing) {
        // Make width dynamic so the SVG fits its parent's width.
        svg.removeAttribute("width");
        // Edge requires us to have a viewBox that gets updated with size changes.
        var isEdge = /Edge\/\d./i.test(navigator.userAgent);
        if (!isEdge) {
          svg.removeAttribute("viewBox");
        }
        var update_for_width_change = function() {
            if (isEdge) {
                svg.attributes.viewBox.value = "0 0 " + svg.width.baseVal.value + " " + svg.height.baseVal.value;
            }

            // Keep consistent padding on left and right of frames container.
            frames.attributes.width.value = svg.width.baseVal.value - xpad * 2;

            // Text truncation needs to be adjusted for the current width.
            var el = frames.children;
            for(var i = 0; i < el.length; i++) {
                update_text(el[i]);
            }

            // Keep search elements at a fixed distance from right edge.
            var svgWidth = svg.width.baseVal.value;
            searchbtn.attributes.x.value = svgWidth - xpad - 100;
            matchedtxt.attributes.x.value = svgWidth - xpad - 100;
        };
        window.addEventListener('resize', function() {
            update_for_width_change();
        });
        // This needs to be done asynchronously for Safari to work.
        setTimeout(function() {
            unzoom();
            update_for_width_change();
            restore_state();
        }, 0);
    } else {
        restore_state();
    }
}
// event listeners
window.addEventListener("click", function(e) {
    var target = find_group(e.target);
    if (target) {
        if (target.nodeName == "a") {
            if (e.ctrlKey === false) return;
            e.preventDefault();
        }
        if (target.classList.contains("parent")) unzoom();
        zoom(target);

        // set parameters for zoom state
        var el = target.querySelector("rect");
        if (el && el.attributes && el.attributes.y && el.attributes._orig_x) {
            var params = get_params()
            params.x = el.attributes._orig_x.value;
            params.y = el.attributes.y.value;
            history.replaceState(null, null, parse_params(params));
        }
    }
    else if (e.target.id == "unzoom") {
        unzoom();

        // remove zoom state
        var params = get_params();
        if (params.x) delete params.x;
        if (params.y) delete params.y;
        history.replaceState(null, null, parse_params(params));
    }
    else if (e.target.id == "search") search_prompt();
}, false)
// mouse-over for info
// show
window.addEventListener("mouseover", function(e) {
    var target = find_group(e.target);
    if (target) details.nodeValue = nametype + " " + g_to_text(target);
}, false)
// clear
window.addEventListener("mouseout", function(e) {
    var target = find_group(e.target);
    if (target) details.nodeValue = ' ';
}, false)
// ctrl-F for search
window.addEventListener("keydown",function (e) {
    if (e.keyCode === 114 || (e.ctrlKey && e.keyCode === 70)) {
        e.preventDefault();
        search_prompt();
    }
}, false)
// functions
function get_params() {
    var params = {};
    var paramsarr = window.location.search.substr(1).split('&');
    for (var i = 0; i < paramsarr.length; ++i) {
        var tmp = paramsarr[i].split("=");
        if (!tmp[0] || !tmp[1]) continue;
        params[tmp[0]]  = decodeURIComponent(tmp[1]);
    }
    return params;
}
function parse_params(params) {
    var uri = "?";
    for (var key in params) {
        uri += key + '=' + encodeURIComponent(params[key]) + '&';
    }
    if (uri.slice(-1) == "&")
        uri = uri.substring(0, uri.length - 1);
    if (uri == '?')
        uri = window.location.href.split('?')[0];
    return uri;
}
function find_child(node, selector) {
    var children = node.querySelectorAll(selector);
    if (children.length) return children[0];
    return;
}
function find_group(node) {
    var parent = node.parentElement;
    if (!parent) return;
    if (parent.id == "frames") return node;
    return find_group(parent);
}
function orig_save(e, attr, val) {
    if (e.attributes["_orig_" + attr] != undefined) return;
    if (e.attributes[attr] == undefined) return;
    if (val == undefined) val = e.attributes[attr].value;
    e.setAttribute("_orig_" + attr, val);
}
function orig_load(e, attr) {
    if (e.attributes["_orig_"+attr] == undefined) return;
    e.attributes[attr].value = e.attributes["_orig_" + attr].value;
    e.removeAttribute("_orig_" + attr);
}
function g_to_text(e) {
    var text = find_child(e, "title").firstChild.nodeValue;
    return (text)
}
function g_to_func(e) {
    var func = g_to_text(e);
    // if there's any manipulation we want to do to the function
    // name before it's searched, do it here before returning.
    return (func);
}
function update_text(e) {
    var r = find_child(e, "rect");
    var t = find_child(e, "text");
    var w = parseFloat(r.attributes.width.value) * frames.attributes.width.value / 100 - 3;
    var txt = find_child(e, "title").textContent.replace(/\([^(]*\)$/,"");
    t.attributes.x.value = format_percent((parseFloat(r.attributes.x.value) + (100 * 3 / frames.attributes.width.value)));
    // Smaller than this size won't fit anything
    if (w < 2 * fontsize * fontwidth) {
        t.textContent = "";
        return;
    }
    t.textContent = txt;
    // Fit in full text width
    if (/^ *\$/.test(txt) || t.getComputedTextLength() < w)
        return;
    if (truncate_text_right) {
        // Truncate the right side of the text.
        for (var x = txt.length - 2; x > 0; x--) {
            if (t.getSubStringLength(0, x + 2) <= w) {
                t.textContent = txt.substring(0, x) + "..";
                return;
            }
        }
    } else {
        // Truncate the left side of the text.
        for (var x = 2; x < txt.length; x++) {
            if (t.getSubStringLength(x - 2, txt.length) <= w) {
                t.textContent = ".." + txt.substring(x, txt.length);
                return;
            }
        }
    }
    t.textContent = "";
}
// zoom
function zoom_reset(e) {
    if (e.attributes != undefined) {
        orig_load(e, "x");
        orig_load(e, "width");
    }
    if (e.childNodes == undefined) return;
    for(var i = 0, c = e.childNodes; i < c.length; i++) {
        zoom_reset(c[i]);
    }
}
function zoom_child(e, x, ratio) {
    if (e.attributes != undefined) {
        if (e.attributes.x != undefined) {
            orig_save(e, "x");
            e.attributes.x.value = format_percent((parseFloat(e.attributes.x.value) - x) * ratio);
            if (e.tagName == "text") {
                e.attributes.x.value = format_percent(parseFloat(find_child(e.parentNode, "rect[x]").attributes.x.value) + (100 * 3 / frames.attributes.width.value));
            }
        }
        if (e.attributes.width != undefined) {
            orig_save(e, "width");
            e.attributes.width.value = format_percent(parseFloat(e.attributes.width.value) * ratio);
        }
    }
    if (e.childNodes == undefined) return;
    for(var i = 0, c = e.childNodes; i < c.length; i++) {
        zoom_child(c[i], x, ratio);
    }
}
function zoom_parent(e) {
    if (e.attributes) {
        if (e.attributes.x != undefined) {
            orig_save(e, "x");
            e.attributes.x.value = "0.0%";
        }
        if (e.attributes.width != undefined) {
            orig_save(e, "width");
            e.attributes.width.value = "100.0%";
        }
    }
    if (e.childNodes == undefined) return;
    for(var i = 0, c = e.childNodes; i < c.length; i++) {
        zoom_parent(c[i]);
    }
}
function zoom(node) {
    var attr = find_child(node, "rect").attributes;
    var width = parseFloat(attr.width.value);
    var xmin = parseFloat(attr.x.value);
    var xmax = xmin + width;
    var ymin = parseFloat(attr.y.value);
    var ratio = 100 / width;
    // XXX: Workaround for JavaScript float issues (fix me)
    var fudge = 0.001;
    unzoombtn.classList.remove("hide");
    var el = frames.children;
    for (var i = 0; i < el.length; i++) {
        var e = el[i];
        var a = find_child(e, "rect").attributes;
        var ex = parseFloat(a.x.value);
        var ew = parseFloat(a.width.value);
        // Is it an ancestor
        if (!inverted) {
            var upstack = parseFloat(a.y.value) > ymin;
        } else {
            var upstack = parseFloat(a.y.value) < ymin;
        }
        if (upstack) {
            // Direct ancestor
            if (ex <= xmin && (ex+ew+fudge) >= xmax) {
                e.classList.add("parent");
                zoom_parent(e);
                update_text(e);
            }
            // not in current path
            else
                e.classList.add("hide");
        }
        // Children maybe
        else {
            // no common path
            if (ex < xmin || ex + fudge >= xmax) {
                e.classList.add("hide");
            }
            else {
                zoom_child(e, xmin, ratio);
                update_text(e);
            }
        }
    }
}
function unzoom() {
    unzoombtn.classList.add("hide");
    var el = frames.children;
    for(var i = 0; i < el.length; i++) {
        el[i].classList.remove("parent");
        el[i].classList.remove("hide");
        zoom_reset(el[i]);
        update_text(el[i]);
    }
}
// search
function reset_search() {
    var el = document.querySelectorAll("#frames rect");
    for (var i = 0; i < el.length; i++) {
        orig_load(el[i], "fill")
    }
    var params = get_params();
    delete params.s;
    history.replaceState(null, null, parse_params(params));
}
function search_prompt() {
    if (!searching) {
        var term = prompt("Enter a search term (regexp " +
            "allowed, eg: ^ext4_)", "");
        if (term != null) {
            search(term)
        }
    } else {
        reset_search();
        searching = 0;
        searchbtn.classList.remove("show");
        searchbtn.firstChild.nodeValue = "Search"
        matchedtxt.classList.add("hide");
        matchedtxt.firstChild.nodeValue = ""
    }
}
function search(term) {
    var re = new RegExp(term);
    var el = frames.children;
    var matches = new Object();
    var maxwidth = 0;
    for (var i = 0; i < el.length; i++) {
        var e = el[i];
        var func = g_to_func(e);
        var rect = find_child(e, "rect");
        if (func == null || rect == null)
            continue;
        // Save max width. Only works as we have a root frame
        var w = parseFloat(rect.attributes.width.value);
        if (w > maxwidth)
            maxwidth = w;
        if (func.match(re)) {
            // highlight
            var x = parseFloat(rect.attributes.x.value);
            orig_save(rect, "fill");
            rect.attributes.fill.value = searchcolor;
            // remember matches
            if (matches[x] == undefined) {
                matches[x] = w;
            } else {
                if (w > matches[x]) {
                    // overwrite with parent
                    matches[x] = w;
                }
            }
            searching = 1;
        }
    }
    if (!searching)
        return;
    var params = get_params();
    params.s = term;
    history.replaceState(null, null, parse_params(params));

    searchbtn.classList.add("show");
    searchbtn.firstChild.nodeValue = "Reset Search";
    // calculate percent matched, excluding vertical overlap
    var count = 0;
    var lastx = -1;
    var lastw = 0;
    var keys = Array();
    for (k in matches) {
        if (matches.hasOwnProperty(k))
            keys.push(k);
    }
    // sort the matched frames by their x location
    // ascending, then width descending
    keys.sort(function(a, b){
        return a - b;
    });
    // Step through frames saving only the biggest bottom-up frames
    // thanks to the sort order. This relies on the tree property
    // where children are always smaller than their parents.
    var fudge = 0.0001;    // JavaScript floating point
    for (var k in keys) {
        var x = parseFloat(keys[k]);
        var w = matches[keys[k]];
        if (x >= lastx + lastw - fudge) {
            count += w;
            lastx = x;
            lastw = w;
        }
    }
    // display matched percent
    matchedtxt.classList.remove("hide");
    var pct = 100 * count / maxwidth;
    if (pct != 100) pct = pct.toFixed(1);
    matchedtxt.firstChild.nodeValue = "Matched: " + pct + "%";
}
function format_percent(n) {
    return n.toFixed(4) + "%";
}
]]></script><rect x="0" y="0" width="100%" height="454" fill="url(#background)"/><text id="title" x="50.0000%" y="24.00">py-spy</text><text id="details" x="10" y="437.00"> </text><text id="unzoom" class="hide" x="10" y="24.00">Reset Zoom</text><text id="search" x="1090" y="24.00">Search</text><text id="matched" x="1090" y="437.00"> </text><svg id="frames" x="10" width="1180"><g><title>&lt;module&gt; (tts_train_speakerid.py:18) (789 samples, 2.55%)</title><rect x="0.4820%" y="52" width="2.5523%" height="15" fill="rgb(227,0,7)"/><text x="0.7320%" y="62.50">&lt;m..</text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:971) (789 samples, 2.55%)</title><rect x="0.4820%" y="68" width="2.5523%" height="15" fill="rgb(217,0,24)"/><text x="0.7320%" y="78.50">_f..</text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:955) (602 samples, 1.95%)</title><rect x="1.0869%" y="84" width="1.9474%" height="15" fill="rgb(221,193,54)"/><text x="1.3369%" y="94.50">_..</text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:665) (601 samples, 1.94%)</title><rect x="1.0902%" y="100" width="1.9442%" height="15" fill="rgb(248,212,6)"/><text x="1.3402%" y="110.50">_..</text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:678) (597 samples, 1.93%)</title><rect x="1.1031%" y="116" width="1.9312%" height="15" fill="rgb(208,68,35)"/><text x="1.3531%" y="126.50">e..</text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (597 samples, 1.93%)</title><rect x="1.1031%" y="132" width="1.9312%" height="15" fill="rgb(232,128,0)"/><text x="1.3531%" y="142.50">_..</text></g><g><title>&lt;module&gt; (tts_interface.py:8) (597 samples, 1.93%)</title><rect x="1.1031%" y="148" width="1.9312%" height="15" fill="rgb(207,160,47)"/><text x="1.3531%" y="158.50">&lt;..</text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:971) (596 samples, 1.93%)</title><rect x="1.1063%" y="164" width="1.9280%" height="15" fill="rgb(228,23,34)"/><text x="1.3563%" y="174.50">_..</text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:955) (596 samples, 1.93%)</title><rect x="1.1063%" y="180" width="1.9280%" height="15" fill="rgb(218,30,26)"/><text x="1.3563%" y="190.50">_..</text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:665) (596 samples, 1.93%)</title><rect x="1.1063%" y="196" width="1.9280%" height="15" fill="rgb(220,122,19)"/><text x="1.3563%" y="206.50">_..</text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:678) (590 samples, 1.91%)</title><rect x="1.1257%" y="212" width="1.9086%" height="15" fill="rgb(250,228,42)"/><text x="1.3757%" y="222.50">e..</text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (590 samples, 1.91%)</title><rect x="1.1257%" y="228" width="1.9086%" height="15" fill="rgb(240,193,28)"/><text x="1.3757%" y="238.50">_..</text></g><g><title>&lt;module&gt; (e2e_tts_fastspeech_speakerid.py:11) (573 samples, 1.85%)</title><rect x="3.1670%" y="212" width="1.8536%" height="15" fill="rgb(216,20,37)"/><text x="3.4170%" y="222.50">&lt;..</text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:971) (573 samples, 1.85%)</title><rect x="3.1670%" y="228" width="1.8536%" height="15" fill="rgb(206,188,39)"/><text x="3.4170%" y="238.50">_..</text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:955) (568 samples, 1.84%)</title><rect x="3.1831%" y="244" width="1.8374%" height="15" fill="rgb(217,207,13)"/><text x="3.4331%" y="254.50">_..</text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:665) (567 samples, 1.83%)</title><rect x="3.1864%" y="260" width="1.8342%" height="15" fill="rgb(231,73,38)"/><text x="3.4364%" y="270.50">_..</text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:678) (566 samples, 1.83%)</title><rect x="3.1896%" y="276" width="1.8309%" height="15" fill="rgb(225,20,46)"/><text x="3.4396%" y="286.50">e..</text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (566 samples, 1.83%)</title><rect x="3.1896%" y="292" width="1.8309%" height="15" fill="rgb(210,31,41)"/><text x="3.4396%" y="302.50">_..</text></g><g><title>&lt;module&gt; (torch/__init__.py:84) (374 samples, 1.21%)</title><rect x="3.8107%" y="308" width="1.2098%" height="15" fill="rgb(221,200,47)"/><text x="4.0607%" y="318.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:971) (374 samples, 1.21%)</title><rect x="3.8107%" y="324" width="1.2098%" height="15" fill="rgb(226,26,5)"/><text x="4.0607%" y="334.50"></text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:955) (374 samples, 1.21%)</title><rect x="3.8107%" y="340" width="1.2098%" height="15" fill="rgb(249,33,26)"/><text x="4.0607%" y="350.50"></text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:658) (374 samples, 1.21%)</title><rect x="3.8107%" y="356" width="1.2098%" height="15" fill="rgb(235,183,28)"/><text x="4.0607%" y="366.50"></text></g><g><title>module_from_spec (&lt;frozen importlib._bootstrap&gt;:571) (374 samples, 1.21%)</title><rect x="3.8107%" y="372" width="1.2098%" height="15" fill="rgb(221,5,38)"/><text x="4.0607%" y="382.50"></text></g><g><title>create_module (&lt;frozen importlib._bootstrap_external&gt;:922) (374 samples, 1.21%)</title><rect x="3.8107%" y="388" width="1.2098%" height="15" fill="rgb(247,18,42)"/><text x="4.0607%" y="398.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (374 samples, 1.21%)</title><rect x="3.8107%" y="404" width="1.2098%" height="15" fill="rgb(241,131,45)"/><text x="4.0607%" y="414.50"></text></g><g><title>main (tts_train_speakerid.py:144) (982 samples, 3.18%)</title><rect x="3.1087%" y="68" width="3.1767%" height="15" fill="rgb(249,31,29)"/><text x="3.3587%" y="78.50">mai..</text></g><g><title>dynamic_import (dynamic_import.py:21) (982 samples, 3.18%)</title><rect x="3.1087%" y="84" width="3.1767%" height="15" fill="rgb(225,111,53)"/><text x="3.3587%" y="94.50">dyn..</text></g><g><title>import_module (importlib/__init__.py:126) (982 samples, 3.18%)</title><rect x="3.1087%" y="100" width="3.1767%" height="15" fill="rgb(238,160,17)"/><text x="3.3587%" y="110.50">imp..</text></g><g><title>_gcd_import (&lt;frozen importlib._bootstrap&gt;:994) (982 samples, 3.18%)</title><rect x="3.1087%" y="116" width="3.1767%" height="15" fill="rgb(214,148,48)"/><text x="3.3587%" y="126.50">_gc..</text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:971) (982 samples, 3.18%)</title><rect x="3.1087%" y="132" width="3.1767%" height="15" fill="rgb(232,36,49)"/><text x="3.3587%" y="142.50">_fi..</text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:955) (978 samples, 3.16%)</title><rect x="3.1217%" y="148" width="3.1637%" height="15" fill="rgb(209,103,24)"/><text x="3.3717%" y="158.50">_fi..</text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:665) (976 samples, 3.16%)</title><rect x="3.1281%" y="164" width="3.1572%" height="15" fill="rgb(229,88,8)"/><text x="3.3781%" y="174.50">_lo..</text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:678) (964 samples, 3.12%)</title><rect x="3.1670%" y="180" width="3.1184%" height="15" fill="rgb(213,181,19)"/><text x="3.4170%" y="190.50">exe..</text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:219) (964 samples, 3.12%)</title><rect x="3.1670%" y="196" width="3.1184%" height="15" fill="rgb(254,191,54)"/><text x="3.4170%" y="206.50">_ca..</text></g><g><title>_apply (torch/nn/modules/module.py:193) (527 samples, 1.70%)</title><rect x="6.7577%" y="164" width="1.7048%" height="15" fill="rgb(241,83,37)"/><text x="7.0077%" y="174.50"></text></g><g><title>convert (torch/nn/modules/module.py:379) (526 samples, 1.70%)</title><rect x="6.7609%" y="180" width="1.7015%" height="15" fill="rgb(233,36,39)"/><text x="7.0109%" y="190.50"></text></g><g><title>train (tts_speakerid.py:324) (545 samples, 1.76%)</title><rect x="6.7059%" y="84" width="1.7630%" height="15" fill="rgb(226,3,54)"/><text x="6.9559%" y="94.50"></text></g><g><title>to (torch/nn/modules/module.py:381) (545 samples, 1.76%)</title><rect x="6.7059%" y="100" width="1.7630%" height="15" fill="rgb(245,192,40)"/><text x="6.9559%" y="110.50"></text></g><g><title>_apply (torch/nn/modules/module.py:187) (545 samples, 1.76%)</title><rect x="6.7059%" y="116" width="1.7630%" height="15" fill="rgb(238,167,29)"/><text x="6.9559%" y="126.50"></text></g><g><title>_apply (torch/nn/modules/module.py:187) (545 samples, 1.76%)</title><rect x="6.7059%" y="132" width="1.7630%" height="15" fill="rgb(232,182,51)"/><text x="6.9559%" y="142.50"></text></g><g><title>_apply (torch/nn/modules/module.py:187) (545 samples, 1.76%)</title><rect x="6.7059%" y="148" width="1.7630%" height="15" fill="rgb(231,60,39)"/><text x="6.9559%" y="158.50"></text></g><g><title>loads (json/__init__.py:349) (832 samples, 2.69%)</title><rect x="8.4851%" y="116" width="2.6914%" height="15" fill="rgb(208,69,12)"/><text x="8.7351%" y="126.50">lo..</text></g><g><title>train (tts_speakerid.py:343) (1,271 samples, 4.11%)</title><rect x="8.4786%" y="84" width="4.1115%" height="15" fill="rgb(235,93,37)"/><text x="8.7286%" y="94.50">trai..</text></g><g><title>load (json/__init__.py:299) (1,270 samples, 4.11%)</title><rect x="8.4819%" y="100" width="4.1083%" height="15" fill="rgb(213,116,39)"/><text x="8.7319%" y="110.50">load..</text></g><g><title>loads (json/__init__.py:354) (437 samples, 1.41%)</title><rect x="11.1765%" y="116" width="1.4136%" height="15" fill="rgb(222,207,29)"/><text x="11.4265%" y="126.50"></text></g><g><title>decode (json/decoder.py:339) (437 samples, 1.41%)</title><rect x="11.1765%" y="132" width="1.4136%" height="15" fill="rgb(206,96,30)"/><text x="11.4265%" y="142.50"></text></g><g><title>raw_decode (json/decoder.py:355) (437 samples, 1.41%)</title><rect x="11.1765%" y="148" width="1.4136%" height="15" fill="rgb(218,138,4)"/><text x="11.4265%" y="158.50"></text></g><g><title>read (kaldiio/compression_header.py:139) (718 samples, 2.32%)</title><rect x="15.3075%" y="308" width="2.3226%" height="15" fill="rgb(250,191,14)"/><text x="15.5575%" y="318.50">r..</text></g><g><title>uint_to_float (kaldiio/compression_header.py:113) (616 samples, 1.99%)</title><rect x="15.6374%" y="324" width="1.9927%" height="15" fill="rgb(239,60,40)"/><text x="15.8874%" y="334.50">u..</text></g><g><title>read_matrix_or_vector (kaldiio/matio.py:383) (1,242 samples, 4.02%)</title><rect x="14.2626%" y="292" width="4.0177%" height="15" fill="rgb(206,27,48)"/><text x="14.5126%" y="302.50">read..</text></g><g><title>read_matrix_or_vector (kaldiio/matio.py:387) (2,603 samples, 8.42%)</title><rect x="18.4130%" y="292" width="8.4204%" height="15" fill="rgb(225,35,8)"/><text x="18.6630%" y="302.50">read_matrix_..</text></g><g><title>char_to_float (kaldiio/compression_header.py:223) (447 samples, 1.45%)</title><rect x="27.0598%" y="308" width="1.4460%" height="15" fill="rgb(250,213,24)"/><text x="27.3098%" y="318.50"></text></g><g><title>char_to_float (kaldiio/compression_header.py:226) (536 samples, 1.73%)</title><rect x="28.5867%" y="308" width="1.7339%" height="15" fill="rgb(247,123,22)"/><text x="28.8367%" y="318.50"></text></g><g><title>char_to_float (kaldiio/compression_header.py:227) (347 samples, 1.12%)</title><rect x="30.3206%" y="308" width="1.1225%" height="15" fill="rgb(231,138,38)"/><text x="30.5706%" y="318.50"></text></g><g><title>char_to_float (kaldiio/compression_header.py:228) (1,296 samples, 4.19%)</title><rect x="31.4431%" y="308" width="4.1924%" height="15" fill="rgb(231,145,46)"/><text x="31.6931%" y="318.50">char_..</text></g><g><title>char_to_float (kaldiio/compression_header.py:231) (611 samples, 1.98%)</title><rect x="35.6549%" y="308" width="1.9765%" height="15" fill="rgb(251,118,11)"/><text x="35.9049%" y="318.50">c..</text></g><g><title>char_to_float (kaldiio/compression_header.py:232) (346 samples, 1.12%)</title><rect x="37.6314%" y="308" width="1.1193%" height="15" fill="rgb(217,147,25)"/><text x="37.8814%" y="318.50"></text></g><g><title>read_matrix_or_vector (kaldiio/matio.py:393) (4,342 samples, 14.05%)</title><rect x="27.0404%" y="292" width="14.0459%" height="15" fill="rgb(247,81,37)"/><text x="27.2904%" y="302.50">read_matrix_or_vector..</text></g><g><title>char_to_float (kaldiio/compression_header.py:233) (722 samples, 2.34%)</title><rect x="38.7507%" y="308" width="2.3356%" height="15" fill="rgb(209,12,38)"/><text x="39.0007%" y="318.50">c..</text></g><g><title>__call__ (io_utils_speakerid.py:118) (8,649 samples, 27.98%)</title><rect x="13.1110%" y="212" width="27.9785%" height="15" fill="rgb(227,1,9)"/><text x="13.3610%" y="222.50">__call__ (io_utils_speakerid.py:118)</text></g><g><title>_get_from_loader (io_utils_speakerid.py:464) (8,644 samples, 27.96%)</title><rect x="13.1272%" y="228" width="27.9623%" height="15" fill="rgb(248,47,43)"/><text x="13.3772%" y="238.50">_get_from_loader (io_utils_speakerid.py:464)</text></g><g><title>load_mat (kaldiio/matio.py:203) (8,487 samples, 27.45%)</title><rect x="13.6350%" y="244" width="27.4545%" height="15" fill="rgb(221,10,30)"/><text x="13.8850%" y="254.50">load_mat (kaldiio/matio.py:203)</text></g><g><title>_load_mat (kaldiio/matio.py:262) (8,473 samples, 27.41%)</title><rect x="13.6803%" y="260" width="27.4092%" height="15" fill="rgb(210,229,1)"/><text x="13.9303%" y="270.50">_load_mat (kaldiio/matio.py:262)</text></g><g><title>read_kaldi (kaldiio/matio.py:339) (8,361 samples, 27.05%)</title><rect x="14.0426%" y="276" width="27.0469%" height="15" fill="rgb(222,148,37)"/><text x="14.2926%" y="286.50">read_kaldi (kaldiio/matio.py:339)</text></g><g><title>update_core (tts_speakerid.py:139) (8,806 samples, 28.49%)</title><rect x="13.0560%" y="132" width="28.4864%" height="15" fill="rgb(234,67,33)"/><text x="13.3060%" y="142.50">update_core (tts_speakerid.py:139)</text></g><g><title>__next__ (chainer/iterators/serial_iterator.py:77) (8,800 samples, 28.47%)</title><rect x="13.0754%" y="148" width="28.4670%" height="15" fill="rgb(247,98,35)"/><text x="13.3254%" y="158.50">__next__ (chainer/iterators/serial_iterator.py..</text></g><g><title>&lt;listcomp&gt; (chainer/iterators/serial_iterator.py:77) (8,799 samples, 28.46%)</title><rect x="13.0786%" y="164" width="28.4638%" height="15" fill="rgb(247,138,52)"/><text x="13.3286%" y="174.50">&lt;listcomp&gt; (chainer/iterators/serial_iterator...</text></g><g><title>__getitem__ (chainer/dataset/dataset_mixin.py:67) (8,798 samples, 28.46%)</title><rect x="13.0819%" y="180" width="28.4605%" height="15" fill="rgb(213,79,30)"/><text x="13.3319%" y="190.50">__getitem__ (chainer/dataset/dataset_mixin.py:..</text></g><g><title>get_example (chainer/datasets/transform_dataset.py:52) (8,798 samples, 28.46%)</title><rect x="13.0819%" y="196" width="28.4605%" height="15" fill="rgb(246,177,23)"/><text x="13.3319%" y="206.50">get_example (chainer/datasets/transform_datase..</text></g><g><title>__call__ (tts_speakerid.py:230) (350 samples, 1.13%)</title><rect x="41.7979%" y="148" width="1.1322%" height="15" fill="rgb(230,62,27)"/><text x="42.0479%" y="158.50"></text></g><g><title>update_core (tts_speakerid.py:140) (548 samples, 1.77%)</title><rect x="41.5424%" y="132" width="1.7727%" height="15" fill="rgb(216,154,8)"/><text x="41.7924%" y="142.50">u..</text></g><g><title>forward (speakerid.py:110) (332 samples, 1.07%)</title><rect x="45.2108%" y="228" width="1.0740%" height="15" fill="rgb(244,35,45)"/><text x="45.4608%" y="238.50"></text></g><g><title>__call__ (torch/nn/modules/module.py:489) (332 samples, 1.07%)</title><rect x="45.2108%" y="244" width="1.0740%" height="15" fill="rgb(251,115,12)"/><text x="45.4608%" y="254.50"></text></g><g><title>forward (torch/nn/modules/container.py:92) (330 samples, 1.07%)</title><rect x="45.2172%" y="260" width="1.0675%" height="15" fill="rgb(240,54,50)"/><text x="45.4672%" y="270.50"></text></g><g><title>__call__ (torch/nn/modules/module.py:489) (326 samples, 1.05%)</title><rect x="45.2302%" y="276" width="1.0546%" height="15" fill="rgb(233,84,52)"/><text x="45.4802%" y="286.50"></text></g><g><title>forward (speakerid.py:188) (1,014 samples, 3.28%)</title><rect x="43.6192%" y="196" width="3.2802%" height="15" fill="rgb(207,117,47)"/><text x="43.8692%" y="206.50">for..</text></g><g><title>__call__ (torch/nn/modules/module.py:489) (1,014 samples, 3.28%)</title><rect x="43.6192%" y="212" width="3.2802%" height="15" fill="rgb(249,43,39)"/><text x="43.8692%" y="222.50">__c..</text></g><g><title>forward (e2e_tts_fastspeech_speakerid.py:349) (1,185 samples, 3.83%)</title><rect x="43.6095%" y="164" width="3.8333%" height="15" fill="rgb(209,38,44)"/><text x="43.8595%" y="174.50">forw..</text></g><g><title>__call__ (torch/nn/modules/module.py:489) (1,182 samples, 3.82%)</title><rect x="43.6192%" y="180" width="3.8236%" height="15" fill="rgb(236,212,23)"/><text x="43.8692%" y="190.50">__ca..</text></g><g><title>make_pad_mask (nets_utils.py:141) (769 samples, 2.49%)</title><rect x="47.4913%" y="228" width="2.4876%" height="15" fill="rgb(242,79,21)"/><text x="47.7413%" y="238.50">ma..</text></g><g><title>make_non_pad_mask (nets_utils.py:247) (787 samples, 2.55%)</title><rect x="47.4719%" y="212" width="2.5459%" height="15" fill="rgb(211,96,35)"/><text x="47.7219%" y="222.50">ma..</text></g><g><title>_source_mask (e2e_tts_fastspeech_speakerid.py:515) (796 samples, 2.57%)</title><rect x="47.4461%" y="196" width="2.5750%" height="15" fill="rgb(253,215,40)"/><text x="47.6961%" y="206.50">_s..</text></g><g><title>_forward (e2e_tts_fastspeech_speakerid.py:302) (803 samples, 2.60%)</title><rect x="47.4461%" y="180" width="2.5976%" height="15" fill="rgb(211,81,21)"/><text x="47.6961%" y="190.50">_f..</text></g><g><title>__call__ (torch/nn/modules/module.py:489) (571 samples, 1.85%)</title><rect x="50.2151%" y="292" width="1.8471%" height="15" fill="rgb(208,190,38)"/><text x="50.4651%" y="302.50">_..</text></g><g><title>forward (encoder_layer.py:50) (597 samples, 1.93%)</title><rect x="50.1375%" y="276" width="1.9312%" height="15" fill="rgb(235,213,38)"/><text x="50.3875%" y="286.50">f..</text></g><g><title>_forward (e2e_tts_fastspeech_speakerid.py:303) (1,039 samples, 3.36%)</title><rect x="50.0437%" y="180" width="3.3610%" height="15" fill="rgb(237,122,38)"/><text x="50.2937%" y="190.50">_fo..</text></g><g><title>__call__ (torch/nn/modules/module.py:489) (1,035 samples, 3.35%)</title><rect x="50.0566%" y="196" width="3.3481%" height="15" fill="rgb(244,218,35)"/><text x="50.3066%" y="206.50">__c..</text></g><g><title>forward (encoder.py:112) (1,017 samples, 3.29%)</title><rect x="50.1148%" y="212" width="3.2899%" height="15" fill="rgb(240,68,47)"/><text x="50.3648%" y="222.50">for..</text></g><g><title>__call__ (torch/nn/modules/module.py:489) (1,015 samples, 3.28%)</title><rect x="50.1213%" y="228" width="3.2834%" height="15" fill="rgb(210,16,53)"/><text x="50.3713%" y="238.50">__c..</text></g><g><title>forward (repeat.py:9) (1,012 samples, 3.27%)</title><rect x="50.1310%" y="244" width="3.2737%" height="15" fill="rgb(235,124,12)"/><text x="50.3810%" y="254.50">for..</text></g><g><title>__call__ (torch/nn/modules/module.py:489) (1,011 samples, 3.27%)</title><rect x="50.1342%" y="260" width="3.2705%" height="15" fill="rgb(224,169,11)"/><text x="50.3842%" y="270.50">__c..</text></g><g><title>make_pad_mask (nets_utils.py:141) (536 samples, 1.73%)</title><rect x="53.4824%" y="228" width="1.7339%" height="15" fill="rgb(250,166,2)"/><text x="53.7324%" y="238.50"></text></g><g><title>make_non_pad_mask (nets_utils.py:247) (556 samples, 1.80%)</title><rect x="53.4597%" y="212" width="1.7986%" height="15" fill="rgb(242,216,29)"/><text x="53.7097%" y="222.50">m..</text></g><g><title>_source_mask (e2e_tts_fastspeech_speakerid.py:515) (569 samples, 1.84%)</title><rect x="53.4435%" y="196" width="1.8406%" height="15" fill="rgb(230,116,27)"/><text x="53.6935%" y="206.50">_..</text></g><g><title>_forward (e2e_tts_fastspeech_speakerid.py:314) (579 samples, 1.87%)</title><rect x="53.4403%" y="180" width="1.8730%" height="15" fill="rgb(228,99,48)"/><text x="53.6903%" y="190.50">_..</text></g><g><title>&lt;listcomp&gt; (e2e_tts_fastspeech_speakerid.py:319) (5,526 samples, 17.88%)</title><rect x="56.4358%" y="228" width="17.8760%" height="15" fill="rgb(253,11,6)"/><text x="56.6858%" y="238.50">&lt;listcomp&gt; (e2e_tts_fastspee..</text></g><g><title>&lt;lambda&gt; (torch/tensor.py:428) (668 samples, 2.16%)</title><rect x="72.1509%" y="244" width="2.1609%" height="15" fill="rgb(247,143,39)"/><text x="72.4009%" y="254.50">&lt;..</text></g><g><title>&lt;lambda&gt; (e2e_tts_fastspeech_speakerid.py:319) (5,843 samples, 18.90%)</title><rect x="55.4427%" y="212" width="18.9014%" height="15" fill="rgb(236,97,10)"/><text x="55.6927%" y="222.50">&lt;lambda&gt; (e2e_tts_fastspeech_s..</text></g><g><title>&lt;listcomp&gt; (e2e_tts_fastspeech_speakerid.py:320) (5,888 samples, 19.05%)</title><rect x="55.3230%" y="196" width="19.0470%" height="15" fill="rgb(233,208,19)"/><text x="55.5730%" y="206.50">&lt;listcomp&gt; (e2e_tts_fastspeech..</text></g><g><title>_forward (e2e_tts_fastspeech_speakerid.py:320) (5,892 samples, 19.06%)</title><rect x="55.3133%" y="180" width="19.0599%" height="15" fill="rgb(216,164,2)"/><text x="55.5633%" y="190.50">_forward (e2e_tts_fastspeech_s..</text></g><g><title>__call__ (torch/nn/modules/module.py:489) (862 samples, 2.79%)</title><rect x="74.6062%" y="292" width="2.7885%" height="15" fill="rgb(220,129,5)"/><text x="74.8562%" y="302.50">__..</text></g><g><title>forward (encoder_layer.py:50) (884 samples, 2.86%)</title><rect x="74.5415%" y="276" width="2.8596%" height="15" fill="rgb(242,17,10)"/><text x="74.7915%" y="286.50">fo..</text></g><g><title>__call__ (torch/nn/modules/module.py:489) (1,239 samples, 4.01%)</title><rect x="74.5382%" y="260" width="4.0080%" height="15" fill="rgb(242,107,0)"/><text x="74.7882%" y="270.50">__ca..</text></g><g><title>_forward (e2e_tts_fastspeech_speakerid.py:323) (1,271 samples, 4.11%)</title><rect x="74.4379%" y="180" width="4.1115%" height="15" fill="rgb(251,28,31)"/><text x="74.6879%" y="190.50">_for..</text></g><g><title>__call__ (torch/nn/modules/module.py:489) (1,270 samples, 4.11%)</title><rect x="74.4412%" y="196" width="4.1083%" height="15" fill="rgb(233,223,10)"/><text x="74.6912%" y="206.50">__ca..</text></g><g><title>forward (encoder.py:112) (1,254 samples, 4.06%)</title><rect x="74.4929%" y="212" width="4.0565%" height="15" fill="rgb(215,21,27)"/><text x="74.7429%" y="222.50">forw..</text></g><g><title>__call__ (torch/nn/modules/module.py:489) (1,253 samples, 4.05%)</title><rect x="74.4962%" y="228" width="4.0533%" height="15" fill="rgb(232,23,21)"/><text x="74.7462%" y="238.50">__ca..</text></g><g><title>forward (repeat.py:9) (1,244 samples, 4.02%)</title><rect x="74.5253%" y="244" width="4.0242%" height="15" fill="rgb(244,5,23)"/><text x="74.7753%" y="254.50">forw..</text></g><g><title>forward (e2e_tts_fastspeech_speakerid.py:351) (9,627 samples, 31.14%)</title><rect x="47.4428%" y="164" width="31.1422%" height="15" fill="rgb(226,81,46)"/><text x="47.6928%" y="174.50">forward (e2e_tts_fastspeech_speakerid.py:351)</text></g><g><title>make_pad_mask (nets_utils.py:141) (4,514 samples, 14.60%)</title><rect x="78.6174%" y="196" width="14.6023%" height="15" fill="rgb(247,70,30)"/><text x="78.8674%" y="206.50">make_pad_mask (nets_ut..</text></g><g><title>forward (e2e_tts_fastspeech_speakerid.py:355) (4,625 samples, 14.96%)</title><rect x="78.5851%" y="164" width="14.9613%" height="15" fill="rgb(212,68,19)"/><text x="78.8351%" y="174.50">forward (e2e_tts_fastsp..</text></g><g><title>make_non_pad_mask (nets_utils.py:247) (4,620 samples, 14.95%)</title><rect x="78.6012%" y="180" width="14.9452%" height="15" fill="rgb(240,187,13)"/><text x="78.8512%" y="190.50">make_non_pad_mask (nets..</text></g><g><title>update_core (tts_speakerid.py:146) (15,727 samples, 50.88%)</title><rect x="43.3151%" y="132" width="50.8750%" height="15" fill="rgb(223,113,26)"/><text x="43.5651%" y="142.50">update_core (tts_speakerid.py:146)</text></g><g><title>__call__ (torch/nn/modules/module.py:489) (15,719 samples, 50.85%)</title><rect x="43.3410%" y="148" width="50.8492%" height="15" fill="rgb(206,192,2)"/><text x="43.5910%" y="158.50">__call__ (torch/nn/modules/module.py:489)</text></g><g><title>update_core (tts_speakerid.py:147) (336 samples, 1.09%)</title><rect x="94.1901%" y="132" width="1.0869%" height="15" fill="rgb(241,108,4)"/><text x="94.4401%" y="142.50"></text></g><g><title>backward (torch/tensor.py:102) (336 samples, 1.09%)</title><rect x="94.1901%" y="148" width="1.0869%" height="15" fill="rgb(247,173,49)"/><text x="94.4401%" y="158.50"></text></g><g><title>backward (torch/autograd/__init__.py:90) (334 samples, 1.08%)</title><rect x="94.1966%" y="164" width="1.0805%" height="15" fill="rgb(224,114,35)"/><text x="94.4466%" y="174.50"></text></g><g><title>clip_grad_norm_ (torch/nn/utils/clip_grad.py:32) (836 samples, 2.70%)</title><rect x="95.3709%" y="148" width="2.7044%" height="15" fill="rgb(245,159,27)"/><text x="95.6209%" y="158.50">cl..</text></g><g><title>norm (torch/tensor.py:252) (823 samples, 2.66%)</title><rect x="95.4129%" y="164" width="2.6623%" height="15" fill="rgb(245,172,44)"/><text x="95.6629%" y="174.50">no..</text></g><g><title>norm (torch/functional.py:715) (821 samples, 2.66%)</title><rect x="95.4194%" y="180" width="2.6558%" height="15" fill="rgb(236,23,11)"/><text x="95.6694%" y="190.50">no..</text></g><g><title>update_core (tts_speakerid.py:156) (982 samples, 3.18%)</title><rect x="95.2771%" y="132" width="3.1767%" height="15" fill="rgb(205,117,38)"/><text x="95.5271%" y="142.50">upd..</text></g><g><title>update_core (tts_speakerid.py:161) (426 samples, 1.38%)</title><rect x="98.4537%" y="132" width="1.3781%" height="15" fill="rgb(237,72,25)"/><text x="98.7037%" y="142.50"></text></g><g><title>step (optimizer.py:26) (426 samples, 1.38%)</title><rect x="98.4537%" y="148" width="1.3781%" height="15" fill="rgb(244,70,9)"/><text x="98.7037%" y="158.50"></text></g><g><title>run (chainer/training/trainer.py:316) (26,874 samples, 86.93%)</title><rect x="12.9751%" y="100" width="86.9343%" height="15" fill="rgb(217,125,39)"/><text x="13.2251%" y="110.50">run (chainer/training/trainer.py:316)</text></g><g><title>update (tts_speakerid.py:166) (26,874 samples, 86.93%)</title><rect x="12.9751%" y="116" width="86.9343%" height="15" fill="rgb(235,36,10)"/><text x="13.2251%" y="126.50">update (tts_speakerid.py:166)</text></g><g><title>&lt;module&gt; (tts_train_speakerid.py:193) (29,960 samples, 96.92%)</title><rect x="3.0376%" y="52" width="96.9172%" height="15" fill="rgb(251,123,47)"/><text x="3.2876%" y="62.50">&lt;module&gt; (tts_train_speakerid.py:193)</text></g><g><title>main (tts_train_speakerid.py:187) (28,953 samples, 93.66%)</title><rect x="6.2951%" y="68" width="93.6596%" height="15" fill="rgb(221,13,13)"/><text x="6.5451%" y="78.50">main (tts_train_speakerid.py:187)</text></g><g><title>train (tts_speakerid.py:487) (26,891 samples, 86.99%)</title><rect x="12.9654%" y="84" width="86.9893%" height="15" fill="rgb(238,131,9)"/><text x="13.2154%" y="94.50">train (tts_speakerid.py:487)</text></g><g><title>all (30,913 samples, 100%)</title><rect x="0.0000%" y="36" width="100.0000%" height="15" fill="rgb(211,50,8)"/><text x="0.2500%" y="46.50"></text></g></svg></svg>